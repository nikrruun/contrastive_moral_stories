{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ddf43e3-ac79-43c0-8bc1-9bf04710909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batch_sizes = {\n",
    "    \"EleutherAI/gpt-neo-1.3B\": 32,\n",
    "    \"EleutherAI/gpt-neo-2.7B\": 16,\n",
    "    \"EleutherAI/gpt-j-6B\": 8,\n",
    "    \"albert-xxlarge-v2\": 64,\n",
    "    \"facebook/opt-6.7b\": 16,\n",
    "}\n",
    "max_gpus = 9\n",
    "\n",
    "classification_column_map = {\n",
    "    \"eval/loss\":\"min\",\n",
    "    \"test/loss\":\"min\",\n",
    "    \"eval/accuracy\":\"max\",\n",
    "    \"test/accuracy\":\"max\",\n",
    "}\n",
    "\n",
    "# \"train/\" prefix due to our two-phase training/evaluation pipeline\n",
    "classification_eval_column_map = {\n",
    "    \"train/original_ms_accuracy\":\"max\",\n",
    "    \"train/anti_ms_accuracy\":\"max\",\n",
    "    \"train/optional_ms_accuracy\":\"max\",\n",
    "    \"train/contra_ms_accuracy\":\"max\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cdc0c3-8f80-4699-bd59-42addd1be028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastmodellib as fml\n",
    "from fastmodellib.log_utils import load_logs_from_dir, agg_logs, get_experiment_duration\n",
    "from fastmodellib.deploy import ModelDeployer, ModelTask, DeepSpeedTask, PythonTask\n",
    "from fastmodellib.deploy import get_device_placement, make_param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a5ecd4-7024-4379-a775-4a9381bd2e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pending 0\n",
      "tasks 0\n",
      "finished 0\n"
     ]
    }
   ],
   "source": [
    "deployer = ModelDeployer()\n",
    "deployer.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0a12dd-ec1a-46eb-81f1-7da58a852d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pending 0\n",
      "tasks 0\n",
      "finished 24\n"
     ]
    }
   ],
   "source": [
    "deployer.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae1fd7e-29e4-4c33-b051-11825a79ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.stop_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77388ad0-769d-4307-8e8b-abcd0d2ebbdb",
   "metadata": {},
   "source": [
    "# Classification\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d476536e-b89e-4c27-932c-16d0bbc450e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_small = [\"distilbert-base-uncased\", \"bert-base-uncased\", \"bert-large-uncased\", \"roberta-large\", \"albert-xxlarge-v2\"]\n",
    "models_large = [\"EleutherAI/gpt-neo-1.3B\", \"EleutherAI/gpt-neo-2.7B\",]\n",
    "\n",
    "models = models_large + models_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c0f92-88ed-423a-b0ae-0ddd667ec8e1",
   "metadata": {},
   "source": [
    "# Original MS\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e425df22-25f4-4754-9d1f-f740a2128094",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=distilbert-base-uncased: batch_size=16, device_bs=16, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=16, device_bs=16, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=16, device_bs=16, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "model=distilbert-base-uncased: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=16, device_bs=16, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=16, device_bs=16, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=16, device_bs=16, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "model=bert-base-uncased: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "Starting deepspeed --include=localhost:0 --master_port=27500 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_1cc77ab0-c170-4b29-843c-875037c97bba.py --deepspeed data/models/test/distilbert-base-uncased/bs16_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:1 --master_port=27501 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_5578d54b-409e-4a7d-b7b4-e6f0950f4536.py --deepspeed data/models/test/distilbert-base-uncased/bs16_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:2 --master_port=27502 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_7a311e54-de79-4dd8-8ee2-697dd8acdcbb.py --deepspeed data/models/test/distilbert-base-uncased/bs16_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:3 --master_port=27503 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_93d1156b-1fb1-4b77-a705-f668898b95bf.py --deepspeed data/models/test/distilbert-base-uncased/bs32_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:4 --master_port=27504 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_bd7c46d7-f838-4212-9f0d-4e0cd7142207.py --deepspeed data/models/test/distilbert-base-uncased/bs32_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:5 --master_port=27505 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_59f99cde-d75b-40c5-bafa-fc9f320f93eb.py --deepspeed data/models/test/distilbert-base-uncased/bs32_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:6 --master_port=27506 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_148896cb-5284-4bf1-8cb3-7cda2c5ec7a1.py --deepspeed data/models/test/distilbert-base-uncased/bs64_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:7 --master_port=27507 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_0f8fc8fd-6f20-49b6-8f18-b52d25d43349.py --deepspeed data/models/test/distilbert-base-uncased/bs64_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:8 --master_port=27508 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_e79bd0c3-2104-493c-b3d5-430698514560.py --deepspeed data/models/test/distilbert-base-uncased/bs64_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:6 --master_port=27506 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_130a66ec-5e8e-4339-80bc-d804e55586f6.py --deepspeed data/models/test/distilbert-base-uncased/bs128_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:8 --master_port=27508 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_30f0f22c-a6ad-47d2-bd0e-cfa55736363c.py --deepspeed data/models/test/distilbert-base-uncased/bs128_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:7 --master_port=27507 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_ab023d7d-91e2-4a2e-ab6e-2fd4b2d29b1a.py --deepspeed data/models/test/distilbert-base-uncased/bs128_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:3 --master_port=27503 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_c014de1f-b244-42dd-a2d9-c533ad08d82e.py --deepspeed data/models/test/bert-base-uncased/bs16_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:4 --master_port=27504 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_933ea948-f260-4ca9-ad50-83580604e505.py --deepspeed data/models/test/bert-base-uncased/bs16_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:5 --master_port=27505 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_18f5e095-8f62-498c-b327-f40377732de0.py --deepspeed data/models/test/bert-base-uncased/bs16_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:8 --master_port=27508 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_a9d3f5c6-4ccf-4e82-8069-88e5fe0ddf9e.py --deepspeed data/models/test/bert-base-uncased/bs32_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:6 --master_port=27506 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_2e2bc2c8-f423-4924-9111-09dad40c2831.py --deepspeed data/models/test/bert-base-uncased/bs32_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:7 --master_port=27507 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_53f38ee0-c8bd-45d8-ba8e-89e57995a2e3.py --deepspeed data/models/test/bert-base-uncased/bs32_lr_5e-05/ds_config.json\n"
     ]
    }
   ],
   "source": [
    "notebook_path = \"train_action_classification.ipynb\"\n",
    "\n",
    "dataset_folder = \"data/contrastive_moral_stories/original_ms/action+norm/norm_distance/\"\n",
    "\n",
    "pgrid = make_param_grid(models, [16, 32, 64, 128], [1e-5, 3e-5, 5e-5])\n",
    "for model_name, batch_size, lr in pgrid:\n",
    "\n",
    "    # find suitable device placement parameters\n",
    "    max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "    min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "    device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "    print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "    training_args = {\n",
    "        \"gradient_accumulation_steps\": grad_acc,\n",
    "        \"per_device_train_batch_size\": device_bs,\n",
    "        \"per_device_eval_batch_size\": device_bs,\n",
    "        \"learning_rate\": lr,\n",
    "    }\n",
    "    logdir = f\"data/models/original_ms/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "    \n",
    "    deployer.enqueue(notebook=notebook_path, backend=\"deepspeed\", training_args=training_args, deepspeed=True,\n",
    "                     num_gpus=num_gpus, logdir=logdir, model_name=model_name, dataset_folder=dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b290cf3-9bf6-4c3d-9715-c306f373602e",
   "metadata": {},
   "source": [
    "# Original MS no pretrain\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ddbbf-5264-4b61-9ea1-950217eaddd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"train_action_classification.ipynb\"\n",
    "\n",
    "dataset = \"original_ms\"\n",
    "\n",
    "dataset_folder = f\"data/contrastive_moral_stories/{dataset}/action+norm/norm_distance/\"\n",
    "\n",
    "for model_name in models_small[::-1]:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # find suitable device placement parameters\n",
    "            max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "            min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "            device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "            print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "            training_args = {\n",
    "                \"gradient_accumulation_steps\": grad_acc,\n",
    "                \"per_device_train_batch_size\": device_bs,\n",
    "                \"per_device_eval_batch_size\": device_bs,\n",
    "                \"learning_rate\": lr,\n",
    "            }\n",
    "            logdir = f\"data/models/{dataset}_no_pretrain/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                                   model_name=model_name, \n",
    "                                                                                   load_pretrained_weights = False,\n",
    "                                                                                   dataset_folder=dataset_folder,)\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c90be2-17b3-4df0-bc66-e81d524cd4e8",
   "metadata": {},
   "source": [
    "# Anti MS\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea19ab2-e16d-479c-baed-e80d259a904f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"train_action_classification.ipynb\"\n",
    "\n",
    "dataset_folder = \"data/contrastive_moral_stories/anti_ms/action+norm/norm_distance/\"\n",
    "\n",
    "for model_name in models:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # find suitable device placement parameters\n",
    "            max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "            min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "            device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "            print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "            training_args = {\n",
    "                \"gradient_accumulation_steps\": grad_acc,\n",
    "                \"per_device_train_batch_size\": device_bs,\n",
    "                \"per_device_eval_batch_size\": device_bs,\n",
    "                \"learning_rate\": lr,\n",
    "            }\n",
    "            logdir = f\"data/models/anti_ms/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                                   model_name=model_name, dataset_folder=dataset_folder)\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffeb1a-bccb-4700-87b9-c8e749109062",
   "metadata": {},
   "source": [
    "# Optional MS\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77511f-4f67-4796-a2de-59a79b2505cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"train_action_classification.ipynb\"\n",
    "\n",
    "dataset_folder = \"data/contrastive_moral_stories/optional_ms/action+norm/norm_distance/\"\n",
    "\n",
    "# deploy training jobs\n",
    "for model_name in models:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # find suitable device placement parameters\n",
    "            max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "            min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "            device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "            print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "            training_args = {\n",
    "                \"gradient_accumulation_steps\": grad_acc,\n",
    "                \"per_device_train_batch_size\": device_bs,\n",
    "                \"per_device_eval_batch_size\": device_bs,\n",
    "                \"learning_rate\": lr,\n",
    "            }\n",
    "            logdir = f\"data/models/optional_ms/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                                   model_name=model_name, dataset_folder=dataset_folder)\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba5110-03b0-4d74-af6b-64c0116dbc4a",
   "metadata": {},
   "source": [
    "# Paradox MS\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2d346-d927-4663-aa38-3ad6cdf5083f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"train_action_classification.ipynb\"\n",
    "\n",
    "dataset = \"contra_ms\"\n",
    "\n",
    "dataset_folder = f\"data/contrastive_moral_stories/{dataset}/action+norm/norm_distance/\"\n",
    "\n",
    "\n",
    "# deploy training jobs\n",
    "for model_name in models_small:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # find suitable device placement parameters\n",
    "            max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "            min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "            device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "            print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "            training_args = {\n",
    "                \"gradient_accumulation_steps\": grad_acc,\n",
    "                \"per_device_train_batch_size\": device_bs,\n",
    "                \"per_device_eval_batch_size\": device_bs,\n",
    "                \"learning_rate\": lr,\n",
    "            }\n",
    "            logdir = f\"data/models/{dataset}/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                                   model_name=model_name, dataset_folder=dataset_folder)\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441bfa59-f3c7-461b-b9a6-8c3706081ab9",
   "metadata": {},
   "source": [
    "# Paradox MS no pretrain\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b899c3-878d-4b58-ab93-c033cf397c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"train_action_classification.ipynb\"\n",
    "\n",
    "dataset = \"contra_ms\"\n",
    "\n",
    "dataset_folder = f\"data/contrastive_moral_stories/{dataset}/action+norm/norm_distance/\"\n",
    "\n",
    "for model_name in [\"bert-base-uncased\"]:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # find suitable device placement parameters\n",
    "            max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "            min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "            device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "            print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "            training_args = {\n",
    "                \"gradient_accumulation_steps\": grad_acc,\n",
    "                \"per_device_train_batch_size\": device_bs,\n",
    "                \"per_device_eval_batch_size\": device_bs,\n",
    "                \"learning_rate\": lr,\n",
    "            }\n",
    "            logdir = f\"data/models/{dataset}_no_pretrain/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                                   model_name=model_name, \n",
    "                                                                                   load_pretrained_weights = False,\n",
    "                                                                                   dataset_folder=dataset_folder,)\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5285b3b-8bb5-4c30-98f7-3a5ef40dd398",
   "metadata": {},
   "source": [
    "# Classification evaluation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6291ae26-c861-4d77-9719-9879ba19daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models_per_dataset(dataset=None, logs=None, metric_key=None):\n",
    "    if dataset is not None:\n",
    "        metric_key = f\"train/{dataset}_accuracy\"\n",
    "        logs = load_logs_from_dir(f\"data/models/{dataset}/\")\n",
    "    elif logs is None or metric_key is None:\n",
    "        raise ValueError(\"Provide either dataset or logs/metric_key\")\n",
    "\n",
    "    results = agg_logs(logs, classification_eval_column_map)\n",
    "    results[\"hyperparameters\"] = results.index.map(lambda x: x.rsplit(\"/\", 1)[1])\n",
    "    groups = results.groupby(results.index.map(lambda x: x.rsplit(\"/\", 1)[0]))\n",
    "    best_runs = groups.agg({metric_key: np.argmax})\n",
    "    best = groups.apply(lambda x: x.iloc[best_runs.loc[x.name][metric_key]])\n",
    "    return best, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54a1c3-15f1-453c-bb51-550ae6729a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### EVALUATION ONLY AFTER TRAINING ###\n",
    "# the big models sometimes OOM if evaluated right after training...\n",
    "\n",
    "notebook_path = \"eval_action_classification.ipynb\"\n",
    "\n",
    "dataset = \"optional_ms\"\n",
    "\n",
    "dataset_folder = f\"data/contrastive_moral_stories/{dataset}/action+norm/norm_distance/\"\n",
    "\n",
    "# deploy eval jobs\n",
    "for model_name in models:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # inference is much nicer on vram...\n",
    "            training_args = {\n",
    "                \"per_device_eval_batch_size\": 4 * max_batch_sizes.get(model_name, batch_size),\n",
    "            }\n",
    "            logdir = f\"data/models/{dataset}/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=1, logdir=logdir,\n",
    "                                                                                   model_name=model_name, override_logdir=False,\n",
    "                                                                                   dataset_folder=dataset_folder, checkpoint=\"first\")\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a99ab3c-05fa-43fa-a8ed-85425a88c223",
   "metadata": {},
   "source": [
    "### Eval for original ms without pretraining\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540cf0a-c9f8-4738-9f46-2c957efb59eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"eval_action_classification.ipynb\"\n",
    "\n",
    "dataset = \"original_ms\"\n",
    "\n",
    "dataset_folder = f\"data/contrastive_moral_stories/{dataset}_no_pretrain/action+norm/norm_distance/\"\n",
    "\n",
    "# deploy eval jobs\n",
    "for model_name in models_small:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # inference is much nicer on vram...\n",
    "            training_args = {\n",
    "                \"per_device_eval_batch_size\": 4 * max_batch_sizes.get(model_name, batch_size),\n",
    "            }\n",
    "            logdir = f\"data/models/{dataset}_no_pretrain/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=1, logdir=logdir,\n",
    "                                                                                   model_name=model_name, override_logdir=False,\n",
    "                                                                                   dataset_folder=dataset_folder, checkpoint=\"first\")\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0db06-9ddf-425f-8c57-d4eeec65d19a",
   "metadata": {},
   "source": [
    "### Eval for paradox ms\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c88d47-8f8e-42fc-a45c-2112ff0dd349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"eval_action_classification.ipynb\"\n",
    "\n",
    "dataset = \"contra_ms\"\n",
    "\n",
    "dataset_folder = f\"data/contrastive_moral_stories/{dataset}/action+norm/norm_distance/\"\n",
    "\n",
    "# deploy eval jobs\n",
    "for model_name in models_small:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # inference is much nicer on vram...\n",
    "            training_args = {\n",
    "                \"per_device_eval_batch_size\": 4 * max_batch_sizes.get(model_name, batch_size),\n",
    "            }\n",
    "            logdir = f\"data/models/{dataset}/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=1, logdir=logdir,\n",
    "                                                                                   model_name=model_name, override_logdir=False,\n",
    "                                                                                   dataset_folder=dataset_folder, checkpoint=\"first\")\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76bf9f5-b1c4-407a-ae19-722a0f82829e",
   "metadata": {},
   "source": [
    "### Eval for paradox ms without pretraining\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d348e87-2cf0-4e0e-8cd7-df0fd1a910ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"eval_action_classification.ipynb\"\n",
    "\n",
    "dataset = \"contra_ms\"\n",
    "\n",
    "dataset_folder = f\"data/contrastive_moral_stories/{dataset}_no_pretrain/action+norm/norm_distance/\"\n",
    "\n",
    "# deploy eval jobs\n",
    "for model_name in models_small:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # inference is much nicer on vram...\n",
    "            training_args = {\n",
    "                \"per_device_eval_batch_size\": 4 * max_batch_sizes.get(model_name, batch_size),\n",
    "            }\n",
    "            logdir = f\"data/models/{dataset}_no_pretrain/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=1, logdir=logdir,\n",
    "                                                                                   model_name=model_name, override_logdir=False,\n",
    "                                                                                   dataset_folder=dataset_folder, checkpoint=\"first\")\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbfb8cc-5b8d-49db-8617-aa7a9ddac9a3",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e808ea4-e3d7-4fd9-aeb1-e0525ce24f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating latex tables...\n",
    "\n",
    "# dict guarantees ordering *phew*\n",
    "latex_columns = {\"train/original_ms_accuracy\":\"\\\\thead{\\\\textit{ms}}\", \n",
    "           \"train/anti_ms_accuracy\":\"\\\\thead{\\\\textit{anti-ms}}\", \n",
    "           \"train/optional_ms_accuracy\":\"\\\\thead{\\\\textit{o.-ms}}\", \n",
    "           \"train/contra_ms_accuracy\":\"\\\\thead{\\\\textit{contra\\\\_ms}}\",\n",
    "}\n",
    "latex_models = [\n",
    "    'distilbert-base-uncased',\n",
    "    'bert-base-uncased',\n",
    "    'bert-large-uncased',\n",
    "    'roberta-large',\n",
    "    'albert-xxlarge-v2',\n",
    "    'EleutherAI/gpt-neo-1.3B',\n",
    "    'EleutherAI/gpt-neo-2.7B',\n",
    "]\n",
    "\n",
    "def format_best_models_table(best):\n",
    "    # prepare single model tables for latex output\n",
    "\n",
    "    def extract_hparams(line):\n",
    "        parts = line.split(\"_\")\n",
    "        return f\"bs {parts[0][2:]}, lr {parts[-1].replace('0','')}\"\n",
    "    \n",
    "    def format_acc(x):\n",
    "        return \"{:,.1f}\".format(100*x)\n",
    "    available_models = [x for x in latex_models if x in best.index]\n",
    "    latex_table = best.rename(columns=latex_columns).loc[available_models]\n",
    "\n",
    "    latex_table = latex_table.style.highlight_max(list(latex_columns.values()), props=\"font-weight: bold;\")\n",
    "    formats = {c:format_acc for c in latex_columns.values()}\n",
    "    formats[\"hyperparameters\"] = extract_hparams\n",
    "    latex_table.format(formatter=formats)\n",
    "    return latex_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8c1bd-db62-428c-8719-fa1045e38654",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Finetuned on Moral Stories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14f127fa-a0ac-45d7-bf99-7161f28f5308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrl}\n",
      " & \\thead{\\textit{ms}} & \\thead{\\textit{anti-ms}} & \\thead{\\textit{o.-ms}} & \\thead{\\textit{contra\\_ms}} & hyperparameters \\\\\n",
      "distilbert-base-uncased & 78.0 & 22.1 & 52.4 & 50.8 & bs 32, lr 5e-5 \\\\\n",
      "bert-base-uncased & 80.7 & 22.2 & 49.0 & 50.6 & bs 16, lr 5e-5 \\\\\n",
      "bert-large-uncased & 82.6 & 19.4 & 53.5 & 51.8 & bs 128, lr 3e-5 \\\\\n",
      "roberta-large & 92.5 & 43.7 & 49.1 & 61.8 & bs 128, lr 3e-5 \\\\\n",
      "albert-xxlarge-v2 & \\bfseries 94.2 & \\bfseries 45.5 & \\bfseries 54.4 & \\bfseries 64.7 & bs 32, lr 1e-5 \\\\\n",
      "EleutherAI/gpt-neo-1.3B & 83.0 & 30.3 & 50.8 & 54.7 & bs 32, lr 1e-5 \\\\\n",
      "EleutherAI/gpt-neo-2.7B & 86.2 & 38.2 & 51.2 & 58.5 & bs 16, lr 1e-5 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6205f_row4_col0, #T_6205f_row4_col1, #T_6205f_row4_col2, #T_6205f_row4_col3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6205f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6205f_level0_col0\" class=\"col_heading level0 col0\" >\\thead{\\textit{ms}}</th>\n",
       "      <th id=\"T_6205f_level0_col1\" class=\"col_heading level0 col1\" >\\thead{\\textit{anti-ms}}</th>\n",
       "      <th id=\"T_6205f_level0_col2\" class=\"col_heading level0 col2\" >\\thead{\\textit{o.-ms}}</th>\n",
       "      <th id=\"T_6205f_level0_col3\" class=\"col_heading level0 col3\" >\\thead{\\textit{contra\\_ms}}</th>\n",
       "      <th id=\"T_6205f_level0_col4\" class=\"col_heading level0 col4\" >hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6205f_level0_row0\" class=\"row_heading level0 row0\" >distilbert-base-uncased</th>\n",
       "      <td id=\"T_6205f_row0_col0\" class=\"data row0 col0\" >78.0</td>\n",
       "      <td id=\"T_6205f_row0_col1\" class=\"data row0 col1\" >22.1</td>\n",
       "      <td id=\"T_6205f_row0_col2\" class=\"data row0 col2\" >52.4</td>\n",
       "      <td id=\"T_6205f_row0_col3\" class=\"data row0 col3\" >50.8</td>\n",
       "      <td id=\"T_6205f_row0_col4\" class=\"data row0 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6205f_level0_row1\" class=\"row_heading level0 row1\" >bert-base-uncased</th>\n",
       "      <td id=\"T_6205f_row1_col0\" class=\"data row1 col0\" >80.7</td>\n",
       "      <td id=\"T_6205f_row1_col1\" class=\"data row1 col1\" >22.2</td>\n",
       "      <td id=\"T_6205f_row1_col2\" class=\"data row1 col2\" >49.0</td>\n",
       "      <td id=\"T_6205f_row1_col3\" class=\"data row1 col3\" >50.6</td>\n",
       "      <td id=\"T_6205f_row1_col4\" class=\"data row1 col4\" >bs 16, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6205f_level0_row2\" class=\"row_heading level0 row2\" >bert-large-uncased</th>\n",
       "      <td id=\"T_6205f_row2_col0\" class=\"data row2 col0\" >82.6</td>\n",
       "      <td id=\"T_6205f_row2_col1\" class=\"data row2 col1\" >19.4</td>\n",
       "      <td id=\"T_6205f_row2_col2\" class=\"data row2 col2\" >53.5</td>\n",
       "      <td id=\"T_6205f_row2_col3\" class=\"data row2 col3\" >51.8</td>\n",
       "      <td id=\"T_6205f_row2_col4\" class=\"data row2 col4\" >bs 128, lr 3e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6205f_level0_row3\" class=\"row_heading level0 row3\" >roberta-large</th>\n",
       "      <td id=\"T_6205f_row3_col0\" class=\"data row3 col0\" >92.5</td>\n",
       "      <td id=\"T_6205f_row3_col1\" class=\"data row3 col1\" >43.7</td>\n",
       "      <td id=\"T_6205f_row3_col2\" class=\"data row3 col2\" >49.1</td>\n",
       "      <td id=\"T_6205f_row3_col3\" class=\"data row3 col3\" >61.8</td>\n",
       "      <td id=\"T_6205f_row3_col4\" class=\"data row3 col4\" >bs 128, lr 3e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6205f_level0_row4\" class=\"row_heading level0 row4\" >albert-xxlarge-v2</th>\n",
       "      <td id=\"T_6205f_row4_col0\" class=\"data row4 col0\" >94.2</td>\n",
       "      <td id=\"T_6205f_row4_col1\" class=\"data row4 col1\" >45.5</td>\n",
       "      <td id=\"T_6205f_row4_col2\" class=\"data row4 col2\" >54.4</td>\n",
       "      <td id=\"T_6205f_row4_col3\" class=\"data row4 col3\" >64.7</td>\n",
       "      <td id=\"T_6205f_row4_col4\" class=\"data row4 col4\" >bs 32, lr 1e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6205f_level0_row5\" class=\"row_heading level0 row5\" >EleutherAI/gpt-neo-1.3B</th>\n",
       "      <td id=\"T_6205f_row5_col0\" class=\"data row5 col0\" >83.0</td>\n",
       "      <td id=\"T_6205f_row5_col1\" class=\"data row5 col1\" >30.3</td>\n",
       "      <td id=\"T_6205f_row5_col2\" class=\"data row5 col2\" >50.8</td>\n",
       "      <td id=\"T_6205f_row5_col3\" class=\"data row5 col3\" >54.7</td>\n",
       "      <td id=\"T_6205f_row5_col4\" class=\"data row5 col4\" >bs 32, lr 1e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6205f_level0_row6\" class=\"row_heading level0 row6\" >EleutherAI/gpt-neo-2.7B</th>\n",
       "      <td id=\"T_6205f_row6_col0\" class=\"data row6 col0\" >86.2</td>\n",
       "      <td id=\"T_6205f_row6_col1\" class=\"data row6 col1\" >38.2</td>\n",
       "      <td id=\"T_6205f_row6_col2\" class=\"data row6 col2\" >51.2</td>\n",
       "      <td id=\"T_6205f_row6_col3\" class=\"data row6 col3\" >58.5</td>\n",
       "      <td id=\"T_6205f_row6_col4\" class=\"data row6 col4\" >bs 16, lr 1e-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7f90aead90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_best, ms_all = get_best_models_per_dataset(\"original_ms\")\n",
    "ms_formatted = format_best_models_table(ms_best)\n",
    "ms_latex = ms_formatted.to_latex(convert_css=True)\n",
    "print(ms_latex)\n",
    "ms_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988c86b-9259-4be1-8501-d5ba38209cdb",
   "metadata": {},
   "source": [
    "### Finetuned on anti-ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfb9f89a-6fb8-4a03-b9d1-9c55d5d983ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrl}\n",
      " & \\thead{\\textit{ms}} & \\thead{\\textit{anti-ms}} & \\thead{\\textit{o.-ms}} & \\thead{\\textit{contra\\_ms}} & hyperparameters \\\\\n",
      "distilbert-base-uncased & 23.6 & 77.0 & 49.4 & 50.0 & bs 64, lr 3e-5 \\\\\n",
      "bert-base-uncased & 30.3 & 80.7 & 53.1 & 54.7 & bs 32, lr 5e-5 \\\\\n",
      "bert-large-uncased & 30.9 & 82.9 & 52.0 & 55.3 & bs 16, lr 1e-5 \\\\\n",
      "roberta-large & 23.1 & 91.4 & 53.8 & 56.1 & bs 16, lr 1e-5 \\\\\n",
      "albert-xxlarge-v2 & 27.8 & \\bfseries 93.0 & \\bfseries 55.9 & \\bfseries 58.9 & bs 32, lr 1e-5 \\\\\n",
      "EleutherAI/gpt-neo-1.3B & 30.4 & 82.4 & 42.8 & 51.9 & bs 32, lr 1e-5 \\\\\n",
      "EleutherAI/gpt-neo-2.7B & \\bfseries 35.4 & 85.0 & 46.5 & 55.6 & bs 16, lr 1e-5 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bf634_row4_col1, #T_bf634_row4_col2, #T_bf634_row4_col3, #T_bf634_row6_col0 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bf634\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bf634_level0_col0\" class=\"col_heading level0 col0\" >\\thead{\\textit{ms}}</th>\n",
       "      <th id=\"T_bf634_level0_col1\" class=\"col_heading level0 col1\" >\\thead{\\textit{anti-ms}}</th>\n",
       "      <th id=\"T_bf634_level0_col2\" class=\"col_heading level0 col2\" >\\thead{\\textit{o.-ms}}</th>\n",
       "      <th id=\"T_bf634_level0_col3\" class=\"col_heading level0 col3\" >\\thead{\\textit{contra\\_ms}}</th>\n",
       "      <th id=\"T_bf634_level0_col4\" class=\"col_heading level0 col4\" >hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bf634_level0_row0\" class=\"row_heading level0 row0\" >distilbert-base-uncased</th>\n",
       "      <td id=\"T_bf634_row0_col0\" class=\"data row0 col0\" >23.6</td>\n",
       "      <td id=\"T_bf634_row0_col1\" class=\"data row0 col1\" >77.0</td>\n",
       "      <td id=\"T_bf634_row0_col2\" class=\"data row0 col2\" >49.4</td>\n",
       "      <td id=\"T_bf634_row0_col3\" class=\"data row0 col3\" >50.0</td>\n",
       "      <td id=\"T_bf634_row0_col4\" class=\"data row0 col4\" >bs 64, lr 3e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf634_level0_row1\" class=\"row_heading level0 row1\" >bert-base-uncased</th>\n",
       "      <td id=\"T_bf634_row1_col0\" class=\"data row1 col0\" >30.3</td>\n",
       "      <td id=\"T_bf634_row1_col1\" class=\"data row1 col1\" >80.7</td>\n",
       "      <td id=\"T_bf634_row1_col2\" class=\"data row1 col2\" >53.1</td>\n",
       "      <td id=\"T_bf634_row1_col3\" class=\"data row1 col3\" >54.7</td>\n",
       "      <td id=\"T_bf634_row1_col4\" class=\"data row1 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf634_level0_row2\" class=\"row_heading level0 row2\" >bert-large-uncased</th>\n",
       "      <td id=\"T_bf634_row2_col0\" class=\"data row2 col0\" >30.9</td>\n",
       "      <td id=\"T_bf634_row2_col1\" class=\"data row2 col1\" >82.9</td>\n",
       "      <td id=\"T_bf634_row2_col2\" class=\"data row2 col2\" >52.0</td>\n",
       "      <td id=\"T_bf634_row2_col3\" class=\"data row2 col3\" >55.3</td>\n",
       "      <td id=\"T_bf634_row2_col4\" class=\"data row2 col4\" >bs 16, lr 1e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf634_level0_row3\" class=\"row_heading level0 row3\" >roberta-large</th>\n",
       "      <td id=\"T_bf634_row3_col0\" class=\"data row3 col0\" >23.1</td>\n",
       "      <td id=\"T_bf634_row3_col1\" class=\"data row3 col1\" >91.4</td>\n",
       "      <td id=\"T_bf634_row3_col2\" class=\"data row3 col2\" >53.8</td>\n",
       "      <td id=\"T_bf634_row3_col3\" class=\"data row3 col3\" >56.1</td>\n",
       "      <td id=\"T_bf634_row3_col4\" class=\"data row3 col4\" >bs 16, lr 1e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf634_level0_row4\" class=\"row_heading level0 row4\" >albert-xxlarge-v2</th>\n",
       "      <td id=\"T_bf634_row4_col0\" class=\"data row4 col0\" >27.8</td>\n",
       "      <td id=\"T_bf634_row4_col1\" class=\"data row4 col1\" >93.0</td>\n",
       "      <td id=\"T_bf634_row4_col2\" class=\"data row4 col2\" >55.9</td>\n",
       "      <td id=\"T_bf634_row4_col3\" class=\"data row4 col3\" >58.9</td>\n",
       "      <td id=\"T_bf634_row4_col4\" class=\"data row4 col4\" >bs 32, lr 1e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf634_level0_row5\" class=\"row_heading level0 row5\" >EleutherAI/gpt-neo-1.3B</th>\n",
       "      <td id=\"T_bf634_row5_col0\" class=\"data row5 col0\" >30.4</td>\n",
       "      <td id=\"T_bf634_row5_col1\" class=\"data row5 col1\" >82.4</td>\n",
       "      <td id=\"T_bf634_row5_col2\" class=\"data row5 col2\" >42.8</td>\n",
       "      <td id=\"T_bf634_row5_col3\" class=\"data row5 col3\" >51.9</td>\n",
       "      <td id=\"T_bf634_row5_col4\" class=\"data row5 col4\" >bs 32, lr 1e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf634_level0_row6\" class=\"row_heading level0 row6\" >EleutherAI/gpt-neo-2.7B</th>\n",
       "      <td id=\"T_bf634_row6_col0\" class=\"data row6 col0\" >35.4</td>\n",
       "      <td id=\"T_bf634_row6_col1\" class=\"data row6 col1\" >85.0</td>\n",
       "      <td id=\"T_bf634_row6_col2\" class=\"data row6 col2\" >46.5</td>\n",
       "      <td id=\"T_bf634_row6_col3\" class=\"data row6 col3\" >55.6</td>\n",
       "      <td id=\"T_bf634_row6_col4\" class=\"data row6 col4\" >bs 16, lr 1e-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7fb178d550>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anti_ms_best, anti_all = get_best_models_per_dataset(\"anti_ms\")\n",
    "anti_formatted = format_best_models_table(anti_ms_best)\n",
    "anti_latex = anti_formatted.to_latex(convert_css=True)\n",
    "print(anti_latex)\n",
    "anti_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675ffb3-2e2e-47ee-bb53-65755209f8e0",
   "metadata": {},
   "source": [
    "### Finetuned on optional-ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ceb64ba0-2aa1-48b3-b0a2-fcd5c5dc09c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrl}\n",
      " & \\thead{\\textit{ms}} & \\thead{\\textit{anti-ms}} & \\thead{\\textit{o.-ms}} & \\thead{\\textit{contra\\_ms}} & hyperparameters \\\\\n",
      "distilbert-base-uncased & \\bfseries 50.0 & \\bfseries 50.0 & \\bfseries 100.0 & \\bfseries 66.7 & bs 32, lr 5e-5 \\\\\n",
      "bert-base-uncased & \\bfseries 50.0 & \\bfseries 50.0 & \\bfseries 100.0 & \\bfseries 66.7 & bs 32, lr 5e-5 \\\\\n",
      "bert-large-uncased & \\bfseries 50.0 & \\bfseries 50.0 & \\bfseries 100.0 & \\bfseries 66.7 & bs 32, lr 5e-5 \\\\\n",
      "roberta-large & \\bfseries 50.0 & \\bfseries 50.0 & \\bfseries 100.0 & \\bfseries 66.7 & bs 32, lr 5e-5 \\\\\n",
      "albert-xxlarge-v2 & \\bfseries 50.0 & \\bfseries 50.0 & \\bfseries 100.0 & \\bfseries 66.7 & bs 32, lr 5e-5 \\\\\n",
      "EleutherAI/gpt-neo-1.3B & \\bfseries 50.0 & \\bfseries 50.0 & \\bfseries 100.0 & \\bfseries 66.7 & bs 32, lr 5e-5 \\\\\n",
      "EleutherAI/gpt-neo-2.7B & \\bfseries 50.0 & \\bfseries 50.0 & \\bfseries 100.0 & \\bfseries 66.7 & bs 32, lr 5e-5 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_09617_row0_col0, #T_09617_row0_col1, #T_09617_row0_col2, #T_09617_row0_col3, #T_09617_row1_col0, #T_09617_row1_col1, #T_09617_row1_col2, #T_09617_row1_col3, #T_09617_row2_col0, #T_09617_row2_col1, #T_09617_row2_col2, #T_09617_row2_col3, #T_09617_row3_col0, #T_09617_row3_col1, #T_09617_row3_col2, #T_09617_row3_col3, #T_09617_row4_col0, #T_09617_row4_col1, #T_09617_row4_col2, #T_09617_row4_col3, #T_09617_row5_col0, #T_09617_row5_col1, #T_09617_row5_col2, #T_09617_row5_col3, #T_09617_row6_col0, #T_09617_row6_col1, #T_09617_row6_col2, #T_09617_row6_col3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_09617\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09617_level0_col0\" class=\"col_heading level0 col0\" >\\thead{\\textit{ms}}</th>\n",
       "      <th id=\"T_09617_level0_col1\" class=\"col_heading level0 col1\" >\\thead{\\textit{anti-ms}}</th>\n",
       "      <th id=\"T_09617_level0_col2\" class=\"col_heading level0 col2\" >\\thead{\\textit{o.-ms}}</th>\n",
       "      <th id=\"T_09617_level0_col3\" class=\"col_heading level0 col3\" >\\thead{\\textit{contra\\_ms}}</th>\n",
       "      <th id=\"T_09617_level0_col4\" class=\"col_heading level0 col4\" >hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09617_level0_row0\" class=\"row_heading level0 row0\" >distilbert-base-uncased</th>\n",
       "      <td id=\"T_09617_row0_col0\" class=\"data row0 col0\" >50.0</td>\n",
       "      <td id=\"T_09617_row0_col1\" class=\"data row0 col1\" >50.0</td>\n",
       "      <td id=\"T_09617_row0_col2\" class=\"data row0 col2\" >100.0</td>\n",
       "      <td id=\"T_09617_row0_col3\" class=\"data row0 col3\" >66.7</td>\n",
       "      <td id=\"T_09617_row0_col4\" class=\"data row0 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09617_level0_row1\" class=\"row_heading level0 row1\" >bert-base-uncased</th>\n",
       "      <td id=\"T_09617_row1_col0\" class=\"data row1 col0\" >50.0</td>\n",
       "      <td id=\"T_09617_row1_col1\" class=\"data row1 col1\" >50.0</td>\n",
       "      <td id=\"T_09617_row1_col2\" class=\"data row1 col2\" >100.0</td>\n",
       "      <td id=\"T_09617_row1_col3\" class=\"data row1 col3\" >66.7</td>\n",
       "      <td id=\"T_09617_row1_col4\" class=\"data row1 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09617_level0_row2\" class=\"row_heading level0 row2\" >bert-large-uncased</th>\n",
       "      <td id=\"T_09617_row2_col0\" class=\"data row2 col0\" >50.0</td>\n",
       "      <td id=\"T_09617_row2_col1\" class=\"data row2 col1\" >50.0</td>\n",
       "      <td id=\"T_09617_row2_col2\" class=\"data row2 col2\" >100.0</td>\n",
       "      <td id=\"T_09617_row2_col3\" class=\"data row2 col3\" >66.7</td>\n",
       "      <td id=\"T_09617_row2_col4\" class=\"data row2 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09617_level0_row3\" class=\"row_heading level0 row3\" >roberta-large</th>\n",
       "      <td id=\"T_09617_row3_col0\" class=\"data row3 col0\" >50.0</td>\n",
       "      <td id=\"T_09617_row3_col1\" class=\"data row3 col1\" >50.0</td>\n",
       "      <td id=\"T_09617_row3_col2\" class=\"data row3 col2\" >100.0</td>\n",
       "      <td id=\"T_09617_row3_col3\" class=\"data row3 col3\" >66.7</td>\n",
       "      <td id=\"T_09617_row3_col4\" class=\"data row3 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09617_level0_row4\" class=\"row_heading level0 row4\" >albert-xxlarge-v2</th>\n",
       "      <td id=\"T_09617_row4_col0\" class=\"data row4 col0\" >50.0</td>\n",
       "      <td id=\"T_09617_row4_col1\" class=\"data row4 col1\" >50.0</td>\n",
       "      <td id=\"T_09617_row4_col2\" class=\"data row4 col2\" >100.0</td>\n",
       "      <td id=\"T_09617_row4_col3\" class=\"data row4 col3\" >66.7</td>\n",
       "      <td id=\"T_09617_row4_col4\" class=\"data row4 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09617_level0_row5\" class=\"row_heading level0 row5\" >EleutherAI/gpt-neo-1.3B</th>\n",
       "      <td id=\"T_09617_row5_col0\" class=\"data row5 col0\" >50.0</td>\n",
       "      <td id=\"T_09617_row5_col1\" class=\"data row5 col1\" >50.0</td>\n",
       "      <td id=\"T_09617_row5_col2\" class=\"data row5 col2\" >100.0</td>\n",
       "      <td id=\"T_09617_row5_col3\" class=\"data row5 col3\" >66.7</td>\n",
       "      <td id=\"T_09617_row5_col4\" class=\"data row5 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09617_level0_row6\" class=\"row_heading level0 row6\" >EleutherAI/gpt-neo-2.7B</th>\n",
       "      <td id=\"T_09617_row6_col0\" class=\"data row6 col0\" >50.0</td>\n",
       "      <td id=\"T_09617_row6_col1\" class=\"data row6 col1\" >50.0</td>\n",
       "      <td id=\"T_09617_row6_col2\" class=\"data row6 col2\" >100.0</td>\n",
       "      <td id=\"T_09617_row6_col3\" class=\"data row6 col3\" >66.7</td>\n",
       "      <td id=\"T_09617_row6_col4\" class=\"data row6 col4\" >bs 32, lr 5e-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7f90b26520>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_ms_best, opt_all = get_best_models_per_dataset(\"optional_ms\")\n",
    "opt_formatted = format_best_models_table(opt_ms_best)\n",
    "opt_latex = opt_formatted.to_latex(convert_css=True)\n",
    "print(opt_latex)\n",
    "opt_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02764023-5df0-4626-bb10-ebcb5c7c34b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-base-uncased & 78.0 & 22.1 & 52.4 & 23.6 & 77.0 & 49.4 &  50.0 &  50.0 &  100.0 \\\\\n",
      "bert-base-uncased & 80.7 & 22.2 & 49.0 & 30.3 & 80.7 & 53.1 &  50.0 &  50.0 &  100.0 \\\\\n",
      "bert-large-uncased & 82.6 & 19.4 & 53.5 & 30.9 & 82.9 & 52.0 &  50.0 &  50.0 &  100.0 \\\\\n",
      "roberta-large & 92.5 & 43.7 & 49.1 & 23.1 & 91.4 & 53.8 &  50.0 &  50.0 &  100.0 \\\\\n",
      "albert-xxlarge-v2 & \\bfseries 94.2 & \\bfseries 45.5 & \\bfseries 54.4 & 27.8 & \\bfseries 93.0 & \\bfseries 55.9 &  50.0 &  50.0 &  100.0 \\\\\n",
      "EleutherAI/gpt-neo-1.3B & 83.0 & 30.3 & 50.8 & 30.4 & 82.4 & 42.8 &  50.0 &  50.0 &  100.0 \\\\\n",
      "EleutherAI/gpt-neo-2.7B & 86.2 & 38.2 & 51.2 & \\bfseries 35.4 & 85.0 & 46.5 &  50.0 &  50.0 &  100.0 \\\\\n"
     ]
    }
   ],
   "source": [
    "# create the joined table\n",
    "\n",
    "ms_lines = ms_formatted.hide(axis=\"index\").hide(subset=[\"\\\\thead{\\\\textit{contra\\\\_ms}}\", \"hyperparameters\"], axis=1).to_latex(convert_css=True).split(\"\\n\")[2:-2]\n",
    "ms_lines = [l+\" & \" + x.replace(\"\\\\\\\\\",\"& \") for l,x in zip(latex_models, ms_lines)]\n",
    "\n",
    "anti_lines = anti_formatted.hide(axis=\"index\").hide(subset=[\"\\\\thead{\\\\textit{contra\\\\_ms}}\", \"hyperparameters\"], axis=1).to_latex(convert_css=True).split(\"\\n\")[2:-2]\n",
    "anti_lines = [x.replace(\"\\\\\\\\\", \"& \") for x in anti_lines]\n",
    "\n",
    "opt_lines = opt_formatted.hide(axis=\"index\").hide(subset=[\"\\\\thead{\\\\textit{contra\\\\_ms}}\", \"hyperparameters\"], axis=1).to_latex(convert_css=True).split(\"\\n\")[2:-2]\n",
    "opt_lines = [x.replace(\"\\\\bfseries\",\"\") for x in opt_lines]\n",
    "\n",
    "table = \"\\n\".join([x + y + z for x,y,z in zip(ms_lines, anti_lines, opt_lines)])\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0af3f-5cd7-4eaa-b559-180cec068f15",
   "metadata": {},
   "source": [
    "## Finetuned on paradox ms (pretrained)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c985a8aa-d21c-46d4-923d-0d42b5696bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      " & \\thead{\\textit{ms}} & \\thead{\\textit{anti-ms}} & \\thead{\\textit{o.-ms}} & \\thead{\\textit{contra\\_ms}} \\\\\n",
      "distilbert-base-uncased & 70.0 & 65.1 & 99.6 & 78.2 \\\\\n",
      "bert-base-uncased & 75.4 & 74.0 & 99.7 & 83.0 \\\\\n",
      "bert-large-uncased & 78.4 & 77.2 & \\bfseries 99.8 & 85.1 \\\\\n",
      "roberta-large & 89.1 & 86.4 & 99.5 & 91.7 \\\\\n",
      "albert-xxlarge-v2 & \\bfseries 90.8 & \\bfseries 88.1 & 99.6 & \\bfseries 92.8 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6e1ed_row2_col2, #T_6e1ed_row4_col0, #T_6e1ed_row4_col1, #T_6e1ed_row4_col3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6e1ed\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e1ed_level0_col0\" class=\"col_heading level0 col0\" >\\thead{\\textit{ms}}</th>\n",
       "      <th id=\"T_6e1ed_level0_col1\" class=\"col_heading level0 col1\" >\\thead{\\textit{anti-ms}}</th>\n",
       "      <th id=\"T_6e1ed_level0_col2\" class=\"col_heading level0 col2\" >\\thead{\\textit{o.-ms}}</th>\n",
       "      <th id=\"T_6e1ed_level0_col3\" class=\"col_heading level0 col3\" >\\thead{\\textit{contra\\_ms}}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e1ed_level0_row0\" class=\"row_heading level0 row0\" >distilbert-base-uncased</th>\n",
       "      <td id=\"T_6e1ed_row0_col0\" class=\"data row0 col0\" >70.0</td>\n",
       "      <td id=\"T_6e1ed_row0_col1\" class=\"data row0 col1\" >65.1</td>\n",
       "      <td id=\"T_6e1ed_row0_col2\" class=\"data row0 col2\" >99.6</td>\n",
       "      <td id=\"T_6e1ed_row0_col3\" class=\"data row0 col3\" >78.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e1ed_level0_row1\" class=\"row_heading level0 row1\" >bert-base-uncased</th>\n",
       "      <td id=\"T_6e1ed_row1_col0\" class=\"data row1 col0\" >75.4</td>\n",
       "      <td id=\"T_6e1ed_row1_col1\" class=\"data row1 col1\" >74.0</td>\n",
       "      <td id=\"T_6e1ed_row1_col2\" class=\"data row1 col2\" >99.7</td>\n",
       "      <td id=\"T_6e1ed_row1_col3\" class=\"data row1 col3\" >83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e1ed_level0_row2\" class=\"row_heading level0 row2\" >bert-large-uncased</th>\n",
       "      <td id=\"T_6e1ed_row2_col0\" class=\"data row2 col0\" >78.4</td>\n",
       "      <td id=\"T_6e1ed_row2_col1\" class=\"data row2 col1\" >77.2</td>\n",
       "      <td id=\"T_6e1ed_row2_col2\" class=\"data row2 col2\" >99.8</td>\n",
       "      <td id=\"T_6e1ed_row2_col3\" class=\"data row2 col3\" >85.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e1ed_level0_row3\" class=\"row_heading level0 row3\" >roberta-large</th>\n",
       "      <td id=\"T_6e1ed_row3_col0\" class=\"data row3 col0\" >89.1</td>\n",
       "      <td id=\"T_6e1ed_row3_col1\" class=\"data row3 col1\" >86.4</td>\n",
       "      <td id=\"T_6e1ed_row3_col2\" class=\"data row3 col2\" >99.5</td>\n",
       "      <td id=\"T_6e1ed_row3_col3\" class=\"data row3 col3\" >91.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e1ed_level0_row4\" class=\"row_heading level0 row4\" >albert-xxlarge-v2</th>\n",
       "      <td id=\"T_6e1ed_row4_col0\" class=\"data row4 col0\" >90.8</td>\n",
       "      <td id=\"T_6e1ed_row4_col1\" class=\"data row4 col1\" >88.1</td>\n",
       "      <td id=\"T_6e1ed_row4_col2\" class=\"data row4 col2\" >99.6</td>\n",
       "      <td id=\"T_6e1ed_row4_col3\" class=\"data row4 col3\" >92.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7f90b264f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrap_best, contrap_all = get_best_models_per_dataset(\"contra_ms\")\n",
    "contrap_formatted = format_best_models_table(contrap_best)\n",
    "contrap_formatted.hide([\"hyperparameters\"], axis=1)\n",
    "contrap_latex = contrap_formatted.to_latex(convert_css=True)\n",
    "print(contrap_latex)\n",
    "contrap_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead5013-d929-4d0f-b9ab-e32f8e86adc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finetuned on original ms (not pretrained)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c93c9f13-5909-45b3-866e-d5b4e091de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      " & \\thead{\\textit{ms}} & \\thead{\\textit{anti-ms}} & \\thead{\\textit{o.-ms}} & \\thead{\\textit{contra\\_ms}} \\\\\n",
      "distilbert-base-uncased & 70.7 & 29.4 & 54.5 & 51.5 \\\\\n",
      "bert-base-uncased & \\bfseries 71.1 & 29.2 & 52.1 & 50.8 \\\\\n",
      "bert-large-uncased & 64.6 & 35.0 & 48.8 & 49.4 \\\\\n",
      "roberta-large & 59.4 & 41.1 & 68.2 & 56.2 \\\\\n",
      "albert-xxlarge-v2 & 50.0 & \\bfseries 50.0 & \\bfseries 100.0 & \\bfseries 66.7 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c2988_row1_col0, #T_c2988_row4_col1, #T_c2988_row4_col2, #T_c2988_row4_col3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c2988\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c2988_level0_col0\" class=\"col_heading level0 col0\" >\\thead{\\textit{ms}}</th>\n",
       "      <th id=\"T_c2988_level0_col1\" class=\"col_heading level0 col1\" >\\thead{\\textit{anti-ms}}</th>\n",
       "      <th id=\"T_c2988_level0_col2\" class=\"col_heading level0 col2\" >\\thead{\\textit{o.-ms}}</th>\n",
       "      <th id=\"T_c2988_level0_col3\" class=\"col_heading level0 col3\" >\\thead{\\textit{contra\\_ms}}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c2988_level0_row0\" class=\"row_heading level0 row0\" >distilbert-base-uncased</th>\n",
       "      <td id=\"T_c2988_row0_col0\" class=\"data row0 col0\" >70.7</td>\n",
       "      <td id=\"T_c2988_row0_col1\" class=\"data row0 col1\" >29.4</td>\n",
       "      <td id=\"T_c2988_row0_col2\" class=\"data row0 col2\" >54.5</td>\n",
       "      <td id=\"T_c2988_row0_col3\" class=\"data row0 col3\" >51.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2988_level0_row1\" class=\"row_heading level0 row1\" >bert-base-uncased</th>\n",
       "      <td id=\"T_c2988_row1_col0\" class=\"data row1 col0\" >71.1</td>\n",
       "      <td id=\"T_c2988_row1_col1\" class=\"data row1 col1\" >29.2</td>\n",
       "      <td id=\"T_c2988_row1_col2\" class=\"data row1 col2\" >52.1</td>\n",
       "      <td id=\"T_c2988_row1_col3\" class=\"data row1 col3\" >50.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2988_level0_row2\" class=\"row_heading level0 row2\" >bert-large-uncased</th>\n",
       "      <td id=\"T_c2988_row2_col0\" class=\"data row2 col0\" >64.6</td>\n",
       "      <td id=\"T_c2988_row2_col1\" class=\"data row2 col1\" >35.0</td>\n",
       "      <td id=\"T_c2988_row2_col2\" class=\"data row2 col2\" >48.8</td>\n",
       "      <td id=\"T_c2988_row2_col3\" class=\"data row2 col3\" >49.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2988_level0_row3\" class=\"row_heading level0 row3\" >roberta-large</th>\n",
       "      <td id=\"T_c2988_row3_col0\" class=\"data row3 col0\" >59.4</td>\n",
       "      <td id=\"T_c2988_row3_col1\" class=\"data row3 col1\" >41.1</td>\n",
       "      <td id=\"T_c2988_row3_col2\" class=\"data row3 col2\" >68.2</td>\n",
       "      <td id=\"T_c2988_row3_col3\" class=\"data row3 col3\" >56.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2988_level0_row4\" class=\"row_heading level0 row4\" >albert-xxlarge-v2</th>\n",
       "      <td id=\"T_c2988_row4_col0\" class=\"data row4 col0\" >50.0</td>\n",
       "      <td id=\"T_c2988_row4_col1\" class=\"data row4 col1\" >50.0</td>\n",
       "      <td id=\"T_c2988_row4_col2\" class=\"data row4 col2\" >100.0</td>\n",
       "      <td id=\"T_c2988_row4_col3\" class=\"data row4 col3\" >66.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7f88faea00>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = load_logs_from_dir(\"data/models/original_ms_no_pretrain/\")\n",
    "originalnp_best, originalnp_all = get_best_models_per_dataset(logs=logs, metric_key=\"train/original_ms_accuracy\")\n",
    "originalnp_formatted = format_best_models_table(originalnp_best)\n",
    "originalnp_formatted.hide([\"hyperparameters\"], axis=1)\n",
    "originalnp_latex = originalnp_formatted.to_latex(convert_css=True)\n",
    "print(originalnp_latex)\n",
    "originalnp_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239daaf2-adab-4d24-b03f-3b0c16ac8f71",
   "metadata": {},
   "source": [
    "## Finetuned on paradox ms (not pretrained)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2be2360-f050-4473-bb2a-9b58f752be54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7a173_row0_col1, #T_7a173_row0_col2, #T_7a173_row0_col3, #T_7a173_row1_col0, #T_7a173_row1_col2, #T_7a173_row2_col2, #T_7a173_row3_col2, #T_7a173_row4_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7a173\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7a173_level0_col0\" class=\"col_heading level0 col0\" >\\thead{\\textit{ms}}</th>\n",
       "      <th id=\"T_7a173_level0_col1\" class=\"col_heading level0 col1\" >\\thead{\\textit{anti-ms}}</th>\n",
       "      <th id=\"T_7a173_level0_col2\" class=\"col_heading level0 col2\" >\\thead{\\textit{o.-ms}}</th>\n",
       "      <th id=\"T_7a173_level0_col3\" class=\"col_heading level0 col3\" >\\thead{\\textit{contra\\_ms}}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7a173_level0_row0\" class=\"row_heading level0 row0\" >distilbert-base-uncased</th>\n",
       "      <td id=\"T_7a173_row0_col0\" class=\"data row0 col0\" >49.9</td>\n",
       "      <td id=\"T_7a173_row0_col1\" class=\"data row0 col1\" >50.6</td>\n",
       "      <td id=\"T_7a173_row0_col2\" class=\"data row0 col2\" >100.0</td>\n",
       "      <td id=\"T_7a173_row0_col3\" class=\"data row0 col3\" >66.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a173_level0_row1\" class=\"row_heading level0 row1\" >bert-base-uncased</th>\n",
       "      <td id=\"T_7a173_row1_col0\" class=\"data row1 col0\" >50.2</td>\n",
       "      <td id=\"T_7a173_row1_col1\" class=\"data row1 col1\" >49.9</td>\n",
       "      <td id=\"T_7a173_row1_col2\" class=\"data row1 col2\" >100.0</td>\n",
       "      <td id=\"T_7a173_row1_col3\" class=\"data row1 col3\" >66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a173_level0_row2\" class=\"row_heading level0 row2\" >bert-large-uncased</th>\n",
       "      <td id=\"T_7a173_row2_col0\" class=\"data row2 col0\" >50.0</td>\n",
       "      <td id=\"T_7a173_row2_col1\" class=\"data row2 col1\" >50.0</td>\n",
       "      <td id=\"T_7a173_row2_col2\" class=\"data row2 col2\" >100.0</td>\n",
       "      <td id=\"T_7a173_row2_col3\" class=\"data row2 col3\" >66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a173_level0_row3\" class=\"row_heading level0 row3\" >roberta-large</th>\n",
       "      <td id=\"T_7a173_row3_col0\" class=\"data row3 col0\" >50.0</td>\n",
       "      <td id=\"T_7a173_row3_col1\" class=\"data row3 col1\" >50.0</td>\n",
       "      <td id=\"T_7a173_row3_col2\" class=\"data row3 col2\" >100.0</td>\n",
       "      <td id=\"T_7a173_row3_col3\" class=\"data row3 col3\" >66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a173_level0_row4\" class=\"row_heading level0 row4\" >albert-xxlarge-v2</th>\n",
       "      <td id=\"T_7a173_row4_col0\" class=\"data row4 col0\" >50.0</td>\n",
       "      <td id=\"T_7a173_row4_col1\" class=\"data row4 col1\" >50.0</td>\n",
       "      <td id=\"T_7a173_row4_col2\" class=\"data row4 col2\" >100.0</td>\n",
       "      <td id=\"T_7a173_row4_col3\" class=\"data row4 col3\" >66.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7f904933d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = load_logs_from_dir(\"data/models/contra_ms_no_pretrain/\")\n",
    "contranp_best, contranp_all = get_best_models_per_dataset(logs=logs, metric_key=\"train/contra_ms_accuracy\")\n",
    "contranp_formatted = format_best_models_table(contranp_best)\n",
    "contranp_formatted.hide([\"hyperparameters\"], axis=1)\n",
    "contranp_latex = contranp_formatted.to_latex(convert_css=True)\n",
    "contranp_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a288b-38fd-40b1-9b7b-deb69e0663e7",
   "metadata": {},
   "source": [
    "# ROT-Generator\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcb8d1-f502-4456-aee6-81e82cca6e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"rot_generator.ipynb\"\n",
    "\n",
    "models = [\"t5-small\", \"facebook/bart-base\", \"facebook/bart-large\", \"t5-base\"][::-1]\n",
    "\n",
    "for model_name in models:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # find suitable device placement parameters\n",
    "            max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "            min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "            device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "            training_args = {\n",
    "                \"gradient_accumulation_steps\": grad_acc,\n",
    "                \"per_device_train_batch_size\": device_bs,\n",
    "                \"per_device_eval_batch_size\": device_bs,\n",
    "                \"learning_rate\": lr,\n",
    "            }\n",
    "            logdir = f\"data/models/rot-generator/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                                   model_name=model_name)\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cad6dd15-1fe7-46e1-87d0-6a0a70402dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train/loss</th>\n",
       "      <th>eval/loss</th>\n",
       "      <th>test/loss</th>\n",
       "      <th>eval/BLEU-4</th>\n",
       "      <th>test/BLEU-4</th>\n",
       "      <th>eval/ROUGE-L</th>\n",
       "      <th>test/ROUGE-L</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>facebook/bart-base</th>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>89.574867</td>\n",
       "      <td>89.626129</td>\n",
       "      <td>95.490997</td>\n",
       "      <td>95.462997</td>\n",
       "      <td>bs16_lr_3e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.033905</td>\n",
       "      <td>89.802925</td>\n",
       "      <td>89.995766</td>\n",
       "      <td>95.553001</td>\n",
       "      <td>95.621002</td>\n",
       "      <td>bs16_lr_3e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5-base</th>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.018570</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>89.012932</td>\n",
       "      <td>89.101349</td>\n",
       "      <td>95.332001</td>\n",
       "      <td>95.336998</td>\n",
       "      <td>bs16_lr_5e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5-small</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.022003</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>88.191483</td>\n",
       "      <td>88.328392</td>\n",
       "      <td>94.953003</td>\n",
       "      <td>94.961998</td>\n",
       "      <td>bs16_lr_5e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train/loss  eval/loss  test/loss  eval/BLEU-4  \\\n",
       "facebook/bart-base       0.0121   0.019440   0.019394    89.574867   \n",
       "facebook/bart-large      0.0100   0.033600   0.033905    89.802925   \n",
       "t5-base                  0.0148   0.018570   0.018326    89.012932   \n",
       "t5-small                 0.0219   0.022003   0.021591    88.191483   \n",
       "\n",
       "                     test/BLEU-4  eval/ROUGE-L  test/ROUGE-L hyperparameters  \n",
       "facebook/bart-base     89.626129     95.490997     95.462997   bs16_lr_3e-05  \n",
       "facebook/bart-large    89.995766     95.553001     95.621002   bs16_lr_3e-05  \n",
       "t5-base                89.101349     95.332001     95.336998   bs16_lr_5e-05  \n",
       "t5-small               88.328392     94.953003     94.961998   bs16_lr_5e-05  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_column_map = {\"train/loss\":\"min\", \"eval/loss\":\"min\", \"test/loss\": \"min\", \n",
    "                         \"eval/BLEU-4\":\"max\", \"test/BLEU-4\":\"max\",\n",
    "                         \"eval/ROUGE-L\":\"max\",\"test/ROUGE-L\":\"max\"}\n",
    "\n",
    "metric_key = \"test/BLEU-4\"\n",
    "\n",
    "logs = load_logs_from_dir(\"data/models/rot-generator/\")\n",
    "results = agg_logs(logs, generator_column_map)\n",
    "results[\"hyperparameters\"] = results.index.map(lambda x: x.rsplit(\"/\", 1)[1])\n",
    "groups = results.groupby(results.index.map(lambda x: x.rsplit(\"/\", 1)[0]))\n",
    "best_runs = groups.agg({metric_key: np.argmax})\n",
    "best = groups.apply(lambda x: x.iloc[best_runs.loc[x.name][metric_key]])\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9876f4-6130-4470-ad99-185d2b5aaef0",
   "metadata": {},
   "source": [
    "# Textual entailment\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e873b-7ae2-4808-8c15-b4bbf2eda394",
   "metadata": {},
   "source": [
    "## Polarity classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006f51e-2530-4c40-9477-2c9c6aa08e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_path = \"train_polarity_classifier.ipynb\"\n",
    "\n",
    "# deploy training jobs\n",
    "for model_name in [\"bert-base-uncased\"]:\n",
    "    for batch_size in [16, 32, 64, 128]:\n",
    "        for lr in [1e-5, 3e-5, 5e-5]:\n",
    "            # find suitable device placement parameters\n",
    "            max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "            min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "            device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "            print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "            training_args = {\n",
    "                \"gradient_accumulation_steps\": grad_acc,\n",
    "                \"per_device_train_batch_size\": device_bs,\n",
    "                \"per_device_eval_batch_size\": device_bs,\n",
    "                \"learning_rate\": lr,\n",
    "            }\n",
    "            logdir = f\"data/models/polarity/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                                   model_name=model_name, dataset_folder=dataset_folder)\n",
    "\n",
    "            t = deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe323eb4-cf1f-4444-95e7-12e054d8ff66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4b982_row0_col0, #T_4b982_row2_col1, #T_4b982_row5_col2, #T_4b982_row8_col2, #T_4b982_row9_col0 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4b982\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4b982_level0_col0\" class=\"col_heading level0 col0\" >train/original_ms_accuracy</th>\n",
       "      <th id=\"T_4b982_level0_col1\" class=\"col_heading level0 col1\" >train/anti_ms_accuracy</th>\n",
       "      <th id=\"T_4b982_level0_col2\" class=\"col_heading level0 col2\" >train/optional_ms_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row0\" class=\"row_heading level0 row0\" >bert-base-uncased/bs32_lr_5e-05</th>\n",
       "      <td id=\"T_4b982_row0_col0\" class=\"data row0 col0\" >0.981000</td>\n",
       "      <td id=\"T_4b982_row0_col1\" class=\"data row0 col1\" >0.954000</td>\n",
       "      <td id=\"T_4b982_row0_col2\" class=\"data row0 col2\" >0.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row1\" class=\"row_heading level0 row1\" >bert-base-uncased/bs16_lr_1e-05</th>\n",
       "      <td id=\"T_4b982_row1_col0\" class=\"data row1 col0\" >0.978000</td>\n",
       "      <td id=\"T_4b982_row1_col1\" class=\"data row1 col1\" >0.959000</td>\n",
       "      <td id=\"T_4b982_row1_col2\" class=\"data row1 col2\" >0.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row2\" class=\"row_heading level0 row2\" >bert-base-uncased/bs16_lr_5e-05</th>\n",
       "      <td id=\"T_4b982_row2_col0\" class=\"data row2 col0\" >0.979000</td>\n",
       "      <td id=\"T_4b982_row2_col1\" class=\"data row2 col1\" >0.962000</td>\n",
       "      <td id=\"T_4b982_row2_col2\" class=\"data row2 col2\" >0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row3\" class=\"row_heading level0 row3\" >bert-base-uncased/bs32_lr_1e-05</th>\n",
       "      <td id=\"T_4b982_row3_col0\" class=\"data row3 col0\" >0.978000</td>\n",
       "      <td id=\"T_4b982_row3_col1\" class=\"data row3 col1\" >0.959000</td>\n",
       "      <td id=\"T_4b982_row3_col2\" class=\"data row3 col2\" >0.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row4\" class=\"row_heading level0 row4\" >bert-base-uncased/bs16_lr_3e-05</th>\n",
       "      <td id=\"T_4b982_row4_col0\" class=\"data row4 col0\" >0.979000</td>\n",
       "      <td id=\"T_4b982_row4_col1\" class=\"data row4 col1\" >0.956000</td>\n",
       "      <td id=\"T_4b982_row4_col2\" class=\"data row4 col2\" >0.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row5\" class=\"row_heading level0 row5\" >bert-base-uncased/bs128_lr_1e-05</th>\n",
       "      <td id=\"T_4b982_row5_col0\" class=\"data row5 col0\" >0.978000</td>\n",
       "      <td id=\"T_4b982_row5_col1\" class=\"data row5 col1\" >0.960000</td>\n",
       "      <td id=\"T_4b982_row5_col2\" class=\"data row5 col2\" >0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row6\" class=\"row_heading level0 row6\" >bert-base-uncased/bs128_lr_3e-05</th>\n",
       "      <td id=\"T_4b982_row6_col0\" class=\"data row6 col0\" >0.977000</td>\n",
       "      <td id=\"T_4b982_row6_col1\" class=\"data row6 col1\" >0.955000</td>\n",
       "      <td id=\"T_4b982_row6_col2\" class=\"data row6 col2\" >0.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row7\" class=\"row_heading level0 row7\" >bert-base-uncased/bs32_lr_3e-05</th>\n",
       "      <td id=\"T_4b982_row7_col0\" class=\"data row7 col0\" >0.980000</td>\n",
       "      <td id=\"T_4b982_row7_col1\" class=\"data row7 col1\" >0.960000</td>\n",
       "      <td id=\"T_4b982_row7_col2\" class=\"data row7 col2\" >0.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row8\" class=\"row_heading level0 row8\" >bert-base-uncased/bs64_lr_3e-05</th>\n",
       "      <td id=\"T_4b982_row8_col0\" class=\"data row8 col0\" >0.977000</td>\n",
       "      <td id=\"T_4b982_row8_col1\" class=\"data row8 col1\" >0.955000</td>\n",
       "      <td id=\"T_4b982_row8_col2\" class=\"data row8 col2\" >0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row9\" class=\"row_heading level0 row9\" >bert-base-uncased/bs64_lr_5e-05</th>\n",
       "      <td id=\"T_4b982_row9_col0\" class=\"data row9 col0\" >0.981000</td>\n",
       "      <td id=\"T_4b982_row9_col1\" class=\"data row9 col1\" >0.955000</td>\n",
       "      <td id=\"T_4b982_row9_col2\" class=\"data row9 col2\" >0.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row10\" class=\"row_heading level0 row10\" >bert-base-uncased/bs128_lr_5e-05</th>\n",
       "      <td id=\"T_4b982_row10_col0\" class=\"data row10 col0\" >0.978000</td>\n",
       "      <td id=\"T_4b982_row10_col1\" class=\"data row10 col1\" >0.957000</td>\n",
       "      <td id=\"T_4b982_row10_col2\" class=\"data row10 col2\" >0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row11\" class=\"row_heading level0 row11\" >bert-base-uncased/bs64_lr_1e-05</th>\n",
       "      <td id=\"T_4b982_row11_col0\" class=\"data row11 col0\" >0.978000</td>\n",
       "      <td id=\"T_4b982_row11_col1\" class=\"data row11 col1\" >0.961000</td>\n",
       "      <td id=\"T_4b982_row11_col2\" class=\"data row11 col2\" >0.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b982_level0_row12\" class=\"row_heading level0 row12\" >roberta-large/bs128_lr_1e-05</th>\n",
       "      <td id=\"T_4b982_row12_col0\" class=\"data row12 col0\" >0.976000</td>\n",
       "      <td id=\"T_4b982_row12_col1\" class=\"data row12 col1\" >0.947000</td>\n",
       "      <td id=\"T_4b982_row12_col2\" class=\"data row12 col2\" >0.854000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1f101cf3d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results\n",
    "l = load_logs_from_dir(\"data/models/polarity/\")\n",
    "a = agg_logs(l, {k:v for k,v in classification_eval_column_map.items() if \"contra\" not in k})\n",
    "a.style.highlight_max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafadca3-f586-4f68-97d0-dc32910bd181",
   "metadata": {},
   "source": [
    "## Train textual entailment model\n",
    "***\n",
    "Requires you to run \"apply_polarity_classifier.ipynb\" first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8878133-aed7-476a-bccd-2bc1f35a7c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = \"train_textual_entailment.ipynb\"\n",
    "\n",
    "# deploy training jobs\n",
    "model_name = \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "for batch_size in [16, 32, 64, 128][-1:]:\n",
    "    for lr in [1e-5, 3e-5, 5e-5][:1]:\n",
    "        # find suitable device placement parameters\n",
    "        max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "        min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "        device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "        print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "        training_args = {\n",
    "            \"gradient_accumulation_steps\": grad_acc,\n",
    "            \"per_device_train_batch_size\": device_bs,\n",
    "            \"per_device_eval_batch_size\": device_bs,\n",
    "            \"learning_rate\": lr,\n",
    "        }\n",
    "        logdir = f\"data/models/textual_entailment/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "        script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                               num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                               model_name=model_name)\n",
    "\n",
    "        t = deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34a9723c-f2c9-4ec0-96d3-3d9e0cdd7f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pending 0\n",
      "tasks 0\n",
      "finished 142\n"
     ]
    }
   ],
   "source": [
    "deployer.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54f31252-89be-4a20-9e25-538f9c7bf5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DeepSpeedTask at 0x7f70cb84e850>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cfb3dda6-b250-4610-9581-ecedb9748c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancelled, shutting down\n",
      "ds terminated\n"
     ]
    }
   ],
   "source": [
    "t.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3527329c-af58-4db3-961c-01efb99f2435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=bert-base-uncased: batch_size=1024, device_bs=512, num_gpus=2, grad_acc=1\n",
      "Starting deepspeed --include=localhost:1,2 --master_port=27501 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_fb0b3201-8707-44fb-8863-8da6fead7a43.py --deepspeed data/models/tests/bert-base-uncased/bs1024_lr_1e-05_wd_0_0/ds_config.json\n"
     ]
    }
   ],
   "source": [
    "notebook_path = \"train_action_classification.ipynb\"\n",
    "\n",
    "dataset_folder = \"data/contrastive_moral_stories/original_ms/action+norm/norm_distance/\"\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "wd = 0.0\n",
    "\n",
    "for batch_size in [1024]:\n",
    "    for lr in [1e-5]:\n",
    "        # find suitable device placement parameters\n",
    "        max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "        min_gpus = 2\n",
    "        device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "        print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "        training_args = {\n",
    "            \"gradient_accumulation_steps\": grad_acc,\n",
    "            \"per_device_train_batch_size\": device_bs,\n",
    "            \"per_device_eval_batch_size\": device_bs,\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"weight_decay\": wd,\n",
    "        }\n",
    "        fltstr = lambda x: str(x).replace('.','_')\n",
    "        logdir = f\"data/models/tests/{model_name}/bs{batch_size}_lr_{fltstr(lr)}_wd_{fltstr(wd)}/\"\n",
    "        script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                               num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                               model_name=model_name, dataset_folder=dataset_folder)\n",
    "\n",
    "        deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57dd7d93-fa98-45ed-a6a8-c5b02062735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=256, device_bs=32, num_gpus=8, grad_acc=1\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=512, device_bs=32, num_gpus=8, grad_acc=2\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "model=EleutherAI/gpt-neo-1.3B: batch_size=1024, device_bs=32, num_gpus=8, grad_acc=4\n",
      "Starting deepspeed --include=localhost:3,4,5,0,1,6,7,8 --master_port=27503 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_d71353f9-ffe3-47e2-ab0b-7ac63cadd1e3.py --deepspeed data/models/tests/EleutherAI/gpt-neo-1.3B/bs256_lr_1e-05_wd_0_01/ds_config.json\n",
      "Starting deepspeed --include=localhost:0,1,2,3,4,5,6,7 --master_port=27500 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_895a52ba-5770-4790-b5c0-b992956ac044.py --deepspeed data/models/tests/EleutherAI/gpt-neo-1.3B/bs256_lr_1e-05_wd_0_05/ds_config.json\n",
      "Starting deepspeed --include=localhost:8,0,1,2,3,4,5,6 --master_port=27508 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_fa3d78f2-c44c-40d8-ab2f-d3da313ff0c9.py --deepspeed data/models/tests/EleutherAI/gpt-neo-1.3B/bs256_lr_1e-05_wd_0_1/ds_config.json\n",
      "Starting deepspeed --include=localhost:7,8,2,3,4,5,0,1 --master_port=27507 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_581a6af4-0deb-4cce-b226-7fa23ec97e65.py --deepspeed data/models/tests/EleutherAI/gpt-neo-1.3B/bs256_lr_3e-05_wd_0_01/ds_config.json\n"
     ]
    }
   ],
   "source": [
    "notebook_path = \"train_action_classification.ipynb\"\n",
    "\n",
    "dataset_folder = \"data/contrastive_moral_stories/original_ms/action+norm/norm_distance/\"\n",
    "\n",
    "model_name = \"facebook/opt-6.7b\"\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "for batch_size in [256, 512, 1024]:\n",
    "    for lr in [1e-5, 3e-5, 5e-5]:\n",
    "        for wd in [0.01, 0.05, 0.1]:\n",
    "            # find suitable device placement parameters\n",
    "            max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "            min_gpus = 2\n",
    "            device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "            print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "            training_args = {\n",
    "                \"gradient_accumulation_steps\": grad_acc,\n",
    "                \"per_device_train_batch_size\": device_bs,\n",
    "                \"per_device_eval_batch_size\": device_bs,\n",
    "                \"learning_rate\": lr,\n",
    "                \"num_train_epochs\": 4,\n",
    "                \"weight_decay\": wd,\n",
    "            }\n",
    "            fltstr = lambda x: str(x).replace('.','_')\n",
    "            logdir = f\"data/models/tests/{model_name}/bs{batch_size}_lr_{fltstr(lr)}_wd_{fltstr(wd)}/\"\n",
    "            script, config, logdir, num_gpus = prepare_deepspeed_run_from_notebook(notebook_path, training_args=training_args, \n",
    "                                                                                   num_gpus=num_gpus, logdir=logdir,\n",
    "                                                                                   model_name=model_name, dataset_folder=dataset_folder)\n",
    "\n",
    "            deployer.enqueue(script, config, logdir, slots=num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e19b24b7-c291-437b-9de3-3dcb7be1bd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 01:18:42.585866: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 05:02:03.846773')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_experiment_duration(\"data/models/tests/EleutherAI/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f727fd7-2ef8-4127-808b-d5d227c75b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancelled, shutting down\n",
      "ds terminated\n"
     ]
    }
   ],
   "source": [
    "deployer.stop_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88504e0e-395b-451a-8485-1541256acc6a",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "***\n",
    "* Try deepspeed autotune for throughput\n",
    "* delete papermill'ed files once process terminates\n",
    "\n",
    "* figure out, what our main argument is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a35366cb-71b1-4633-8d77-92557900cce7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=roberta-large: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "Starting deepspeed --include=localhost:4 --master_port=27504 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_3c5117c2-c6c6-4b50-a735-c7ed91f4a346.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs32_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:2 --master_port=27502 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_eec1a840-d37a-4047-b435-d4bde554c047.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs32_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:5 --master_port=27505 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_d619088d-5902-4b52-8c8c-b81ea76c114c.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs32_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:3 --master_port=27503 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_a3682a34-2d4c-4975-8d24-1aabcc18ac17.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs64_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:8 --master_port=27508 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_1f1d307f-84cc-4c2f-a2ec-c1d39e78ad71.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs64_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:0 --master_port=27500 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_bc2a4b66-ab99-40bb-bc4c-9c1829367d98.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs64_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:1 --master_port=27501 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_a6bb1eab-b108-4044-9c9c-3bcba783c37a.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs128_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:7 --master_port=27507 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_9a2a42ff-e336-4fc4-baf4-40a90dac5f9b.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs128_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:6 --master_port=27506 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_d3195a76-423a-4fc0-8c54-8fd5f98ce336.py --deepspeed data/models/anti_ms_judgments_only/roberta-large/bs128_lr_5e-05/ds_config.json\n"
     ]
    }
   ],
   "source": [
    "notebook_path = \"train_action_classification_judgments_only.ipynb\"\n",
    "\n",
    "\n",
    "pgrid = make_param_grid([\"roberta-large\"], [32, 64, 128], [1e-5, 3e-5, 5e-5])\n",
    "for model_name, batch_size, lr in pgrid:\n",
    "\n",
    "    # find suitable device placement parameters\n",
    "    max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "    min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "    device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "    print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "    training_args = {\n",
    "        \"gradient_accumulation_steps\": grad_acc,\n",
    "        \"per_device_train_batch_size\": device_bs,\n",
    "        \"per_device_eval_batch_size\": device_bs,\n",
    "        \"learning_rate\": lr,\n",
    "        \"load_best_model_at_end\": True,\n",
    "    }\n",
    "    logdir = f\"data/models/anti_ms_judgments_only/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "    \n",
    "    deployer.enqueue(notebook=notebook_path, backend=\"deepspeed\", training_args=training_args, deepspeed=True,\n",
    "                     num_gpus=num_gpus, logdir=logdir, model_name=model_name, action_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab0fcd74-0a22-4dee-8368-8b70c14fe365",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=roberta-large: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=32, device_bs=32, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=64, device_bs=64, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "model=roberta-large: batch_size=128, device_bs=128, num_gpus=1, grad_acc=1\n",
      "Running training and evaluation in the same process might cause cuda OOMs!\n",
      "Starting deepspeed --include=localhost:1 --master_port=27501 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_4b28144c-90bb-40b8-959a-25394f09ef3c.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs32_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:6 --master_port=27506 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_c20d9d27-0839-4ce8-b452-5c2400ba0209.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs32_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:7 --master_port=27507 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_ef0771d6-7b40-45f2-9006-c040c407fa9a.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs32_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:0 --master_port=27500 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_23566972-e0cb-4a7d-bc17-59f2330a3c02.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs64_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:8 --master_port=27508 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_7c277036-2f5e-4691-840c-baa3ba00c746.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs64_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:3 --master_port=27503 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_f89622e7-906c-4380-9c5c-fd5d1b71b7de.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs64_lr_5e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:2 --master_port=27502 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_7d44c255-eeba-4386-9bc0-975791fbcb6b.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs128_lr_1e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:4 --master_port=27504 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_47a369e8-1a51-42ac-bbbb-c3bf1c7ed002.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs128_lr_3e-05/ds_config.json\n",
      "Starting deepspeed --include=localhost:5 --master_port=27505 /home/kiehne/jupyter-lab/workspace/emnlp2022/train_action_classification_judgments_only_5d64c0f1-21ea-487f-877f-fef63265e87a.py --deepspeed data/models/anti_ms_actions_only/roberta-large/bs128_lr_5e-05/ds_config.json\n"
     ]
    }
   ],
   "source": [
    "notebook_path = \"train_action_classification_judgments_only.ipynb\"\n",
    "\n",
    "\n",
    "pgrid = make_param_grid([\"roberta-large\"], [32, 64, 128], [1e-5, 3e-5, 5e-5])\n",
    "for model_name, batch_size, lr in pgrid:\n",
    "\n",
    "    # find suitable device placement parameters\n",
    "    max_batch_size = max_batch_sizes.get(model_name, batch_size)\n",
    "    min_gpus = 1 if not \"EleutherAI\" in model_name else 2\n",
    "    device_bs, num_gpus, grad_acc = get_device_placement(batch_size, max_batch_size, max_gpus, min_gpus)\n",
    "\n",
    "    print(f\"model={model_name}: batch_size={batch_size}, device_bs={device_bs}, num_gpus={num_gpus}, grad_acc={grad_acc}\")\n",
    "    training_args = {\n",
    "        \"gradient_accumulation_steps\": grad_acc,\n",
    "        \"per_device_train_batch_size\": device_bs,\n",
    "        \"per_device_eval_batch_size\": device_bs,\n",
    "        \"learning_rate\": lr,\n",
    "        \"load_best_model_at_end\": True,\n",
    "    }\n",
    "    logdir = f\"data/models/anti_ms_actions_only/{model_name}/bs{batch_size}_lr_{str(lr).replace('.','_')}/\"\n",
    "    \n",
    "    deployer.enqueue(notebook=notebook_path, backend=\"deepspeed\", training_args=training_args, deepspeed=True,\n",
    "                     num_gpus=num_gpus, logdir=logdir, model_name=model_name, action_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be3e6705-5e7f-4b2b-83c6-d3f603bbb7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/train_accuracy</th>\n",
       "      <th>test/dev_accuracy</th>\n",
       "      <th>test/test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs32_lr_5e-05</th>\n",
       "      <td>0.993895</td>\n",
       "      <td>0.796482</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs32_lr_1e-05</th>\n",
       "      <td>0.910920</td>\n",
       "      <td>0.795477</td>\n",
       "      <td>0.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs128_lr_1e-05</th>\n",
       "      <td>0.854269</td>\n",
       "      <td>0.776382</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs128_lr_3e-05</th>\n",
       "      <td>0.934191</td>\n",
       "      <td>0.796985</td>\n",
       "      <td>0.7905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs32_lr_3e-05</th>\n",
       "      <td>0.986888</td>\n",
       "      <td>0.802010</td>\n",
       "      <td>0.7935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs64_lr_3e-05</th>\n",
       "      <td>0.961015</td>\n",
       "      <td>0.796482</td>\n",
       "      <td>0.7890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs64_lr_5e-05</th>\n",
       "      <td>0.979882</td>\n",
       "      <td>0.808040</td>\n",
       "      <td>0.7885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs128_lr_5e-05</th>\n",
       "      <td>0.970423</td>\n",
       "      <td>0.797487</td>\n",
       "      <td>0.7885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs64_lr_1e-05</th>\n",
       "      <td>0.874337</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs32_lr_5e-05</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs32_lr_1e-05</th>\n",
       "      <td>0.961415</td>\n",
       "      <td>0.845226</td>\n",
       "      <td>0.8395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs128_lr_1e-05</th>\n",
       "      <td>0.933140</td>\n",
       "      <td>0.842211</td>\n",
       "      <td>0.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs128_lr_3e-05</th>\n",
       "      <td>0.972976</td>\n",
       "      <td>0.840704</td>\n",
       "      <td>0.8450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs32_lr_3e-05</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs64_lr_3e-05</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs64_lr_5e-05</th>\n",
       "      <td>0.945851</td>\n",
       "      <td>0.830151</td>\n",
       "      <td>0.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs128_lr_5e-05</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs64_lr_1e-05</th>\n",
       "      <td>0.914423</td>\n",
       "      <td>0.845226</td>\n",
       "      <td>0.8270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  test/train_accuracy  test/dev_accuracy  \\\n",
       "bert-base-uncased/bs32_lr_5e-05              0.993895           0.796482   \n",
       "bert-base-uncased/bs32_lr_1e-05              0.910920           0.795477   \n",
       "bert-base-uncased/bs128_lr_1e-05             0.854269           0.776382   \n",
       "bert-base-uncased/bs128_lr_3e-05             0.934191           0.796985   \n",
       "bert-base-uncased/bs32_lr_3e-05              0.986888           0.802010   \n",
       "bert-base-uncased/bs64_lr_3e-05              0.961015           0.796482   \n",
       "bert-base-uncased/bs64_lr_5e-05              0.979882           0.808040   \n",
       "bert-base-uncased/bs128_lr_5e-05             0.970423           0.797487   \n",
       "bert-base-uncased/bs64_lr_1e-05              0.874337           0.788442   \n",
       "roberta-large/bs32_lr_5e-05                  0.500000           0.500000   \n",
       "roberta-large/bs32_lr_1e-05                  0.961415           0.845226   \n",
       "roberta-large/bs128_lr_1e-05                 0.933140           0.842211   \n",
       "roberta-large/bs128_lr_3e-05                 0.972976           0.840704   \n",
       "roberta-large/bs32_lr_3e-05                  0.500000           0.500000   \n",
       "roberta-large/bs64_lr_3e-05                  0.500000           0.500000   \n",
       "roberta-large/bs64_lr_5e-05                  0.945851           0.830151   \n",
       "roberta-large/bs128_lr_5e-05                 0.500000           0.500000   \n",
       "roberta-large/bs64_lr_1e-05                  0.914423           0.845226   \n",
       "\n",
       "                                  test/test_accuracy  \n",
       "bert-base-uncased/bs32_lr_5e-05               0.7835  \n",
       "bert-base-uncased/bs32_lr_1e-05               0.7805  \n",
       "bert-base-uncased/bs128_lr_1e-05              0.7600  \n",
       "bert-base-uncased/bs128_lr_3e-05              0.7905  \n",
       "bert-base-uncased/bs32_lr_3e-05               0.7935  \n",
       "bert-base-uncased/bs64_lr_3e-05               0.7890  \n",
       "bert-base-uncased/bs64_lr_5e-05               0.7885  \n",
       "bert-base-uncased/bs128_lr_5e-05              0.7885  \n",
       "bert-base-uncased/bs64_lr_1e-05               0.7750  \n",
       "roberta-large/bs32_lr_5e-05                   0.5000  \n",
       "roberta-large/bs32_lr_1e-05                   0.8395  \n",
       "roberta-large/bs128_lr_1e-05                  0.8400  \n",
       "roberta-large/bs128_lr_3e-05                  0.8450  \n",
       "roberta-large/bs32_lr_3e-05                   0.5000  \n",
       "roberta-large/bs64_lr_3e-05                   0.5000  \n",
       "roberta-large/bs64_lr_5e-05                   0.8120  \n",
       "roberta-large/bs128_lr_5e-05                  0.5000  \n",
       "roberta-large/bs64_lr_1e-05                   0.8270  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = load_logs_from_dir(\"data/models/anti_ms_judgments_only/\")\n",
    "agg_logs(logs, {\"test/train_accuracy\": \"max\", \"test/dev_accuracy\":\"max\", \"test/test_accuracy\":\"max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d882dfa0-ce8f-4f03-aab7-eb6fb82157ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/train_accuracy</th>\n",
       "      <th>test/dev_accuracy</th>\n",
       "      <th>test/test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs32_lr_5e-05</th>\n",
       "      <td>0.989290</td>\n",
       "      <td>0.799497</td>\n",
       "      <td>0.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs32_lr_1e-05</th>\n",
       "      <td>0.902362</td>\n",
       "      <td>0.794975</td>\n",
       "      <td>0.7815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs128_lr_1e-05</th>\n",
       "      <td>0.844010</td>\n",
       "      <td>0.775377</td>\n",
       "      <td>0.7695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs128_lr_3e-05</th>\n",
       "      <td>0.941397</td>\n",
       "      <td>0.802513</td>\n",
       "      <td>0.7860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs32_lr_3e-05</th>\n",
       "      <td>0.977730</td>\n",
       "      <td>0.799497</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs64_lr_3e-05</th>\n",
       "      <td>0.959163</td>\n",
       "      <td>0.802513</td>\n",
       "      <td>0.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs64_lr_5e-05</th>\n",
       "      <td>0.980733</td>\n",
       "      <td>0.802010</td>\n",
       "      <td>0.7850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs128_lr_5e-05</th>\n",
       "      <td>0.979181</td>\n",
       "      <td>0.801508</td>\n",
       "      <td>0.7810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased/bs64_lr_1e-05</th>\n",
       "      <td>0.879642</td>\n",
       "      <td>0.790452</td>\n",
       "      <td>0.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs32_lr_5e-05</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs32_lr_1e-05</th>\n",
       "      <td>0.965019</td>\n",
       "      <td>0.850251</td>\n",
       "      <td>0.8495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs128_lr_1e-05</th>\n",
       "      <td>0.930087</td>\n",
       "      <td>0.840201</td>\n",
       "      <td>0.8350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs128_lr_3e-05</th>\n",
       "      <td>0.983635</td>\n",
       "      <td>0.845226</td>\n",
       "      <td>0.8435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs32_lr_3e-05</th>\n",
       "      <td>0.967571</td>\n",
       "      <td>0.842714</td>\n",
       "      <td>0.8260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs64_lr_3e-05</th>\n",
       "      <td>0.978030</td>\n",
       "      <td>0.846231</td>\n",
       "      <td>0.8410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs64_lr_5e-05</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs128_lr_5e-05</th>\n",
       "      <td>0.987339</td>\n",
       "      <td>0.840201</td>\n",
       "      <td>0.8290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-large/bs64_lr_1e-05</th>\n",
       "      <td>0.943649</td>\n",
       "      <td>0.841709</td>\n",
       "      <td>0.8415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  test/train_accuracy  test/dev_accuracy  \\\n",
       "bert-base-uncased/bs32_lr_5e-05              0.989290           0.799497   \n",
       "bert-base-uncased/bs32_lr_1e-05              0.902362           0.794975   \n",
       "bert-base-uncased/bs128_lr_1e-05             0.844010           0.775377   \n",
       "bert-base-uncased/bs128_lr_3e-05             0.941397           0.802513   \n",
       "bert-base-uncased/bs32_lr_3e-05              0.977730           0.799497   \n",
       "bert-base-uncased/bs64_lr_3e-05              0.959163           0.802513   \n",
       "bert-base-uncased/bs64_lr_5e-05              0.980733           0.802010   \n",
       "bert-base-uncased/bs128_lr_5e-05             0.979181           0.801508   \n",
       "bert-base-uncased/bs64_lr_1e-05              0.879642           0.790452   \n",
       "roberta-large/bs32_lr_5e-05                  0.500000           0.500000   \n",
       "roberta-large/bs32_lr_1e-05                  0.965019           0.850251   \n",
       "roberta-large/bs128_lr_1e-05                 0.930087           0.840201   \n",
       "roberta-large/bs128_lr_3e-05                 0.983635           0.845226   \n",
       "roberta-large/bs32_lr_3e-05                  0.967571           0.842714   \n",
       "roberta-large/bs64_lr_3e-05                  0.978030           0.846231   \n",
       "roberta-large/bs64_lr_5e-05                  0.500000           0.500000   \n",
       "roberta-large/bs128_lr_5e-05                 0.987339           0.840201   \n",
       "roberta-large/bs64_lr_1e-05                  0.943649           0.841709   \n",
       "\n",
       "                                  test/test_accuracy  \n",
       "bert-base-uncased/bs32_lr_5e-05               0.7805  \n",
       "bert-base-uncased/bs32_lr_1e-05               0.7815  \n",
       "bert-base-uncased/bs128_lr_1e-05              0.7695  \n",
       "bert-base-uncased/bs128_lr_3e-05              0.7860  \n",
       "bert-base-uncased/bs32_lr_3e-05               0.7835  \n",
       "bert-base-uncased/bs64_lr_3e-05               0.7840  \n",
       "bert-base-uncased/bs64_lr_5e-05               0.7850  \n",
       "bert-base-uncased/bs128_lr_5e-05              0.7810  \n",
       "bert-base-uncased/bs64_lr_1e-05               0.7755  \n",
       "roberta-large/bs32_lr_5e-05                   0.5000  \n",
       "roberta-large/bs32_lr_1e-05                   0.8495  \n",
       "roberta-large/bs128_lr_1e-05                  0.8350  \n",
       "roberta-large/bs128_lr_3e-05                  0.8435  \n",
       "roberta-large/bs32_lr_3e-05                   0.8260  \n",
       "roberta-large/bs64_lr_3e-05                   0.8410  \n",
       "roberta-large/bs64_lr_5e-05                   0.5000  \n",
       "roberta-large/bs128_lr_5e-05                  0.8290  \n",
       "roberta-large/bs64_lr_1e-05                   0.8415  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = load_logs_from_dir(\"data/models/anti_ms_actions_only/\")\n",
    "agg_logs(logs, {\"test/train_accuracy\": \"max\", \"test/dev_accuracy\":\"max\", \"test/test_accuracy\":\"max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "436bd1e0-8009-4404-8c52-56d8be235016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancelled, shutting down\n",
      "cancelled, shutting down\n",
      "cancelled, shutting down\n",
      "cancelled, shutting down\n",
      "cancelled, shutting down\n",
      "cancelled, shutting down\n",
      "cancelled, shutting down\n",
      "cancelled, shutting down\n",
      "cancelled, shutting down\n",
      "ds terminated\n",
      "ds terminated\n",
      "ds terminated\n",
      "ds terminated\n",
      "ds terminated\n",
      "ds terminated\n",
      "ds terminated\n",
      "ds terminated\n",
      "ds terminated\n"
     ]
    }
   ],
   "source": [
    "deployer.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4b97f-1346-4668-a609-123a68a5a4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
