{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047f67c2-ba69-415e-be50-9655d4cf2784",
   "metadata": {},
   "source": [
    "# Prepare Experiment & Deepspeed config (**MANDATORY**)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f9ab32-f86e-4830-ac5f-0b9dcd9fceb6",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 24,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 5e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 5e8,\n",
    "        \"contiguous_gradients\": True,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\",\n",
    "        },\n",
    "        \"offload_params\": {\n",
    "            \"device\": \"none\"\n",
    "        },\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 200,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"per_device_train_batch_size\": 8,\n",
    "    \"per_device_eval_batch_size\": 256,\n",
    "    \"fp16\": True,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"logging_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"save_total_limit\": 1,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"eval_BLEU-4\",\n",
    "    \"greater_is_better\": True,\n",
    "}\n",
    "\n",
    "num_gpus = 1\n",
    "model_name =\"t5-small\"\n",
    "logdir = \"data/models/t5-small/rot-generator/\"\n",
    "override_logdir = True\n",
    "block_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b194b8-be8d-44e3-90dc-27f3fe4d05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6193ccdf-bc57-42e5-9b21-ade4db40bee5",
   "metadata": {},
   "source": [
    "# Tokenize the dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c709d7-c6a8-4ac4-9280-9b3066705abd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[43mmodel_name\u001b[49m, model_max_length\u001b[38;5;241m=\u001b[39mblock_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ffca712-77e3-4491-8218-9cd492342c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_social_chem101():\n",
    "    a = pd.read_csv(\"data/social-chem-101/social-chem-101.v1.0.tsv\", sep=\"\\t\")\n",
    "    return a\n",
    "\n",
    "social_chem = load_social_chem101()\n",
    "#social_chem = social_chem[social_chem[\"split\"] == \"train\"]\n",
    "social_chem = social_chem.dropna(subset=[\"rot-categorization\", \"rot-judgment\", \"action\", \"rot-agree\"])\n",
    "social_chem = social_chem[social_chem[\"rot-agree\"] >= 3.0]\n",
    "social_chem = social_chem[social_chem[\"rot-bad\"] == 0]\n",
    "social_chem = social_chem[social_chem[\"rot-categorization\"].apply(lambda x: \"morality-ethics\" in x or \"social-norms\" in x)]\n",
    "social_chem = social_chem[social_chem[\"rot-judgment\"].apply(lambda x: \"{\" not in x)]\n",
    "social_chem = social_chem[social_chem.apply(lambda x: max(len(x[\"rot\"]), len(x[\"action\"]) + len(x[\"rot-judgment\"])) <= block_size, axis=1)]\n",
    "social_chem = social_chem[[\"action\", \"rot-judgment\", \"rot\"]].groupby(\"rot\", as_index=False).nth(0)\n",
    "\n",
    "train, dev = train_test_split(social_chem, test_size=0.2, random_state=42)\n",
    "dev, test = train_test_split(dev, test_size=0.5, random_state=42)\n",
    "\n",
    "dataset = datasets.DatasetDict()\n",
    "dataset[\"train\"] = datasets.Dataset.from_pandas(train)\n",
    "dataset[\"dev\"] = datasets.Dataset.from_pandas(dev)\n",
    "dataset[\"test\"] = datasets.Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119c029-6f78-4b9e-bf5d-7a2e722232f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input(samples):\n",
    "    inp = tokenizer(samples[\"rot-judgment\"], samples[\"action\"], truncation=True, padding=\"max_length\", max_length=block_size)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        out = tokenizer(samples[\"rot\"], truncation=True, padding=\"max_length\", max_length=block_size)\n",
    "    inp[\"labels\"] = out[\"input_ids\"]\n",
    "    return inp\n",
    "\n",
    "tokenized_data = dataset.map(tokenize_input, batched=True, batch_size=10000).shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8cb7c-de02-4e36-bd84-d422d42dce04",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9963960-f5f4-46c1-852c-3cec290c2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc523063-8995-46bc-bfe1-69fd8defb637",
   "metadata": {},
   "source": [
    "# Prepare Trainer\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154cada-1bb8-40c2-b8c0-9fb9e79d5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Moral Stories Github:\n",
    "# https://github.com/demelin/moral_stories/blob/master/experiments/utils.py\n",
    "\n",
    "import sacrebleu\n",
    "from sacrerouge.metrics import Rouge\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    return compute_gen_metrics(decoded_preds, decoded_labels)\n",
    "\n",
    "def compute_gen_metrics(preds, targets):\n",
    "    \"\"\" Aggregates generation metrics. \"\"\"\n",
    "    assert len(preds) == len(targets)\n",
    "    return {'BLEU-4': compute_bleu(preds, targets),\n",
    "            'ROUGE-L': compute_rouge(preds, targets)}    \n",
    "\n",
    "def compute_bleu(preds, targets):\n",
    "    \"\"\" Computes corpus-level BLEU for the generated sequences. \"\"\"\n",
    "    targets = [targets]\n",
    "    bleu = sacrebleu.corpus_bleu(preds, targets)\n",
    "    return bleu.score\n",
    "\n",
    "def compute_rouge(preds, targets):\n",
    "    \"\"\" Computes ROUGE-L for the generated sequences. \"\"\"\n",
    "    rouge = Rouge(compute_rouge_l=True)\n",
    "    rouge_out = rouge.evaluate(preds, [[tgt] for tgt in targets])\n",
    "    return rouge_out[0]['rouge-l']['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20433c0-600e-4f92-8a17-2daac9946753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "import torch\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=logdir,\n",
    "    overwrite_output_dir=override_logdir,\n",
    "    logging_dir=logdir,\n",
    "    deepspeed= logdir + \"/ds_config.json\",\n",
    "    report_to=\"tensorboard\",\n",
    "    predict_with_generate=True,\n",
    "    **training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68bcb6-8ea7-4518-a54b-bf08bd3cfe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1bee44-9cd0-42a6-b82a-c2d289b63aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f13a10-c44f-409e-9d22-c79af220e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_data[\"test\"], metric_key_prefix=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
