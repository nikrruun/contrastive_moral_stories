{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047f67c2-ba69-415e-be50-9655d4cf2784",
   "metadata": {},
   "source": [
    "# Prepare Experiment & Deepspeed config (**MANDATORY**)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6f9ab32-f86e-4830-ac5f-0b9dcd9fceb6",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 24,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 5e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 5e8,\n",
    "        \"contiguous_gradients\": True,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\",\n",
    "        },\n",
    "        \"offload_params\": {\n",
    "            \"device\": \"none\"\n",
    "        },\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 200,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    \"save_steps\": 100,\n",
    "    \"logging_steps\": 50,\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"per_device_train_batch_size\": 8,\n",
    "    \"per_device_eval_batch_size\": 64,\n",
    "    \"fp16\": True,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_total_limit\": 2,\n",
    "    \"lr_scheduler_type\": \"cosine\"\n",
    "}\n",
    "\n",
    "num_gpus = 1\n",
    "model_name =\"t5-small\"\n",
    "#model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
    "#model_name = \"EleutherAI/gpt-j-6B\"\n",
    "logdir = \"data/models/t5-small/rot-splitter/\"\n",
    "override_logdir = True\n",
    "block_size = 128\n",
    "out_token = \"[ROT]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "28b194b8-be8d-44e3-90dc-27f3fe4d05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6193ccdf-bc57-42e5-9b21-ade4db40bee5",
   "metadata": {},
   "source": [
    "# Tokenize the dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2c709d7-c6a8-4ac4-9280-9b3066705abd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=block_size)\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\":[out_token]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a081de-4d84-42c9-ab0f-8f084ed46451",
   "metadata": {},
   "source": [
    "input_ids = tokenizer([\"Hello [ROT] Again\"])[\"input_ids\"]\n",
    "print(input_ids)\n",
    "tokenizer.decode(input_ids[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0340ca-d994-4cfa-b7c4-36f153f40415",
   "metadata": {},
   "source": [
    "tokenizer.decode([7204, 1], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ffca712-77e3-4491-8218-9cd492342c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_social_chem101():\n",
    "    a = pd.read_csv(\"data/social-chem-101/social-chem-101.v1.0.tsv\", sep=\"\\t\")\n",
    "    return a\n",
    "\n",
    "social_chem = load_social_chem101()\n",
    "#social_chem = social_chem[social_chem[\"split\"] == \"train\"]\n",
    "social_chem = social_chem.dropna(subset=[\"rot-categorization\", \"rot-judgment\", \"action\", \"rot-agree\"])\n",
    "social_chem = social_chem[social_chem[\"rot-agree\"] >= 3.0]\n",
    "social_chem = social_chem[social_chem[\"rot-bad\"] == 0]\n",
    "social_chem = social_chem[social_chem[\"rot-categorization\"].apply(lambda x: \"morality-ethics\" in x or \"social-norms\" in x)]\n",
    "social_chem = social_chem[social_chem[\"rot-judgment\"].apply(lambda x: \"{\" not in x)]\n",
    "social_chem = social_chem[social_chem.apply(lambda x: max(len(x[\"rot\"]), len(x[\"action\"]) + len(x[\"rot-judgment\"])) <= block_size, axis=1)]\n",
    "social_chem = social_chem[[\"action\", \"rot-judgment\", \"rot\"]].groupby(\"rot\", as_index=False).nth(0)\n",
    "\n",
    "train, dev = train_test_split(social_chem, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa1315fe-c847-40c3-84dd-4ea86459e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.Dataset.from_pandas(train).shuffle()\n",
    "dev_data = datasets.Dataset.from_pandas(dev).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3119c029-6f78-4b9e-bf5d-7a2e722232f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ed2a8777844b8db747816464117fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc45036343742c190bcd9a2771c7b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_input(samples):\n",
    "    inp = tokenizer(samples[\"rot\"], truncation=True, padding=\"max_length\", max_length=block_size)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        x = [judgment + \" \" + out_token + \" \" +  action for judgment, action in zip(samples[\"rot-judgment\"], samples[\"action\"])]\n",
    "        out = tokenizer(x, truncation=True, padding=\"max_length\", max_length=block_size)\n",
    "    inp[\"labels\"] = out[\"input_ids\"]\n",
    "    return inp\n",
    "\n",
    "tokenized_train = train_data.map(tokenize_input, batched=True, batch_size=10000)\n",
    "tokenized_dev = dev_data.map(tokenize_input, batched=True, batch_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8cb7c-de02-4e36-bd84-d422d42dce04",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9963960-f5f4-46c1-852c-3cec290c2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc523063-8995-46bc-bfe1-69fd8defb637",
   "metadata": {},
   "source": [
    "# Prepare Trainer\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20433c0-600e-4f92-8a17-2daac9946753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "import torch\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=logdir,\n",
    "    overwrite_output_dir=override_logdir,\n",
    "    logging_dir=logdir,\n",
    "    deepspeed= logdir + \"/ds_config.json\",\n",
    "    report_to=\"tensorboard\",\n",
    "    predict_with_generate=True,\n",
    "    **training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68bcb6-8ea7-4518-a54b-bf08bd3cfe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb4bfe37-44d6-4e14-bb7c-ff35aa8c2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"data/models/t5-small/rot-splitter/bs128_lr_0_0001/checkpoint-1100/\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "073d0f94-87e7-4eb4-9402-ce760cacbbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>rot-judgment</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66880</th>\n",
       "      <td>not inviting all of their family to an event can appear as petty or disloyal to the rest of their family.</td>\n",
       "      <td>refrain from</td>\n",
       "      <td>&lt;pad&gt; can appear as petty or disloyal to the rest of their family.[ROT] People who don't invite all of their family to an event&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87715</th>\n",
       "      <td>appreciating the life you have</td>\n",
       "      <td>You should</td>\n",
       "      <td>&lt;pad&gt; you should[ROT] appréciing the life you have&lt;/s&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267810</th>\n",
       "      <td>being grateful when someone helps to save the company you work for.</td>\n",
       "      <td>It's understandable</td>\n",
       "      <td>&lt;pad&gt; It's understoodable[ROT] being grateful when someone helps to save the company you work for.&lt;/s&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92868</th>\n",
       "      <td>being angry when your ex best friend ruins your life.</td>\n",
       "      <td>It's understandable</td>\n",
       "      <td>&lt;pad&gt; It's understoodable[ROT] being angry when your ex best friend ruins your life.&lt;/s&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           action  \\\n",
       "66880   not inviting all of their family to an event can appear as petty or disloyal to the rest of their family.   \n",
       "87715                                                                              appreciating the life you have   \n",
       "267810                                        being grateful when someone helps to save the company you work for.   \n",
       "92868                                                       being angry when your ex best friend ruins your life.   \n",
       "\n",
       "               rot-judgment  \\\n",
       "66880          refrain from   \n",
       "87715            You should   \n",
       "267810  It's understandable   \n",
       "92868   It's understandable   \n",
       "\n",
       "                                                                                                                                                                               split  \n",
       "66880                                            <pad> can appear as petty or disloyal to the rest of their family.[ROT] People who don't invite all of their family to an event</s>  \n",
       "87715      <pad> you should[ROT] appréciing the life you have</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  \n",
       "267810  <pad> It's understoodable[ROT] being grateful when someone helps to save the company you work for.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  \n",
       "92868            <pad> It's understoodable[ROT] being angry when your ex best friend ruins your life.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = [66880, 87715, 267810, 92868]\n",
    "sample = dev.sample(10).copy()\n",
    "sample = dev.loc[k]\n",
    "x = tokenizer(sample[\"rot\"].to_list(), padding=\"max_length\", return_tensors=\"pt\")\n",
    "x = {k:v.cuda() for k,v in x.items()}\n",
    "y = model.generate(**x, min_length=1, max_length=128, top_p=0.95, top_k=50, \n",
    "                   num_beams=10, temperature=1, force_words_ids=[tokenizer.additional_special_tokens_ids])\n",
    "sample[\"split\"] = tokenizer.batch_decode(y, skip_special_tokens=False)\n",
    "sample[[\"action\", \"rot-judgment\", \"split\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6db66-7005-4efd-b474-f3f27b9dbf15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
