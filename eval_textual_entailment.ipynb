{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047f67c2-ba69-415e-be50-9655d4cf2784",
   "metadata": {},
   "source": [
    "# Prepare Experiment & Deepspeed config (**MANDATORY**)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f9ab32-f86e-4830-ac5f-0b9dcd9fceb6",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "checkpoint = \"first\"\n",
    "model_name = \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "tokenizer_name = \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "# ynie config: entailment is on 0, neutral on 1 and contrad. on 2\n",
    "# ours is 0: contrad., 1 entail, so we need to map\n",
    "class_map = {0:2, 1:0, 2:1}\n",
    "block_size = 128\n",
    "logdir = \"data/models/textual_entailment/ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli/bs128_lr_1e-05/\"\n",
    "polarity_model_dir = \"data/models/polarity/bert-base-uncased/bs128_lr_1e-05/\"\n",
    "\n",
    "override_logdir = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b194b8-be8d-44e3-90dc-27f3fe4d05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import datasets\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faaf667f-472b-4027-8781-b030a953c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_social_chem101():\n",
    "    a = pd.read_csv(\"data/social-chem-101/social-chem-101.v1.0.tsv\", sep=\"\\t\")\n",
    "    return a\n",
    "\n",
    "social_chem = load_social_chem101()\n",
    "social_chem = social_chem[social_chem[\"split\"] == \"train\"]\n",
    "social_chem = social_chem.dropna(subset=[\"rot-categorization\", \"rot-judgment\", \"action\", \"rot-agree\", \"action-moral-judgment\"])\n",
    "social_chem = social_chem[social_chem[\"rot-agree\"] >= 3.0]\n",
    "social_chem = social_chem[social_chem[\"rot-bad\"] == 0]\n",
    "social_chem = social_chem[social_chem[\"rot-categorization\"].apply(lambda x: \"morality-ethics\" in x or \"social-norms\" in x)]\n",
    "social_chem = social_chem[social_chem[\"rot-judgment\"].apply(lambda x: \"{\" not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ffca712-77e3-4491-8218-9cd492342c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the rot-action from social chemistry\n",
    "def to_entailment_task(t):\n",
    "    t = t.merge(social_chem[[\"rot\",\"action\",\"action-moral-judgment\"]], suffixes=(\"\",\"_norm\"), left_on=\"norm\", right_on=\"rot\")\n",
    "    t = t.groupby([\"ID\"]).nth(0)\n",
    "    t[\"polarity\"] = (t[\"action-moral-judgment\"] > 0).astype(\"int\")\n",
    "    t[\"action_polarity\"] = t[\"label\"]\n",
    "    # 1: entailing, 0: contradicting\n",
    "    t[\"label\"] = (t[\"polarity\"] == t[\"action_polarity\"]).astype(\"int\").apply(class_map.get)\n",
    "    return t\n",
    "\n",
    "\n",
    "def load_action_norm_split(path):\n",
    "    train, dev, test = [pd.read_json(f\"{path}{x}.jsonl\", lines=True) for x in [\"train\", \"dev\", \"test\"]]\n",
    "\n",
    "    # construct dataframes that can actually be used\n",
    "    assign_action = lambda x: x[\"moral_action\"] if x[\"label\"] == 1 else x[\"immoral_action\"]\n",
    "    train[\"action\"] = train.apply(assign_action, axis=1)\n",
    "    dev[\"action\"] = dev.apply(assign_action, axis=1)\n",
    "    test[\"action\"] = test.apply(assign_action, axis=1)\n",
    "    return train, dev, test\n",
    "\n",
    "# used for testing\n",
    "train, dev, test = load_action_norm_split(\"data/contrastive_moral_stories/original_ms/action+norm/norm_distance/\")\n",
    "opt_train, opt_dev, opt_test = load_action_norm_split(\"data/contrastive_moral_stories/optional_ms/action+norm/norm_distance/\")\n",
    "anti_train, anti_dev, anti_test = load_action_norm_split(\"data/contrastive_moral_stories/anti_ms/action+norm/norm_distance/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b17bbf54-a8c0-46a0-ae7b-dd45d4acecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities = {k:pd.read_csv(polarity_model_dir + k + \".csv\") for k in [\"original_ms\", \"anti_ms\", \"optional_ms\", \"contra_ms\"]}\n",
    "entailments = pd.read_csv(logdir + \"original_ms_te_applied.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c2ba448-8b56-4ca9-ae0a-8714244b7b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_ms without fine-tuning 0.782\n",
      "original_ms with fine-tuning 0.901\n"
     ]
    }
   ],
   "source": [
    "original_ms_pred = entailments.merge(polarities[\"original_ms\"][[\"norm\", \"y_pred\"]], on=\"norm\")\n",
    "original_ms_no_ft = ((original_ms_pred[\"y_pred\"] == original_ms_pred[\"te_pred_no_ft\"]) == original_ms_pred[\"action_polarity\"]).mean()\n",
    "original_ms_with_ft = ((original_ms_pred[\"y_pred\"] == original_ms_pred[\"te_pred_ft\"]) == original_ms_pred[\"action_polarity\"]).mean()\n",
    "print(\"original_ms without fine-tuning\", original_ms_no_ft)\n",
    "print(\"original_ms with fine-tuning\", original_ms_with_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "994e1a30-f6c1-4385-948e-dfa9e07fd818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anti_ms without fine-tuning 0.767\n",
      "anti_ms with fine-tuning 0.8785\n"
     ]
    }
   ],
   "source": [
    "anti_ms_pred = polarities[\"anti_ms\"][[\"ID\",\"norm\", \"y_pred\"]].merge(test, on=\"ID\", suffixes=(\"_flipped\",\"\"))[[\"norm_flipped\",\"norm\", \"y_pred\"]].merge(entailments, on=\"norm\")\n",
    "anti_ms_pred[\"polarity\"] = anti_ms_pred[\"polarity\"].apply(lambda x: int(not x))\n",
    "anti_ms_pred[\"action_polarity\"] = anti_ms_pred[\"action_polarity\"].apply(lambda x: int(not x))\n",
    "\n",
    "anti_ms_no_ft = ((anti_ms_pred[\"y_pred\"] == anti_ms_pred[\"te_pred_no_ft\"]) == anti_ms_pred[\"action_polarity\"]).mean()\n",
    "anti_ms_with_ft = ((anti_ms_pred[\"y_pred\"] == anti_ms_pred[\"te_pred_ft\"]) == anti_ms_pred[\"action_polarity\"]).mean()\n",
    "\n",
    "print(\"anti_ms without fine-tuning\", anti_ms_no_ft)\n",
    "print(\"anti_ms with fine-tuning\", anti_ms_with_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "04340ec8-63d6-478c-9365-be3eb5b4902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optional_ms, independent of textual entailment: 0.992\n"
     ]
    }
   ],
   "source": [
    "# optional cases are somewhat dull as they do not need any textual inference...\n",
    "optional_results = (polarities[\"optional_ms\"][\"label\"] == polarities[\"optional_ms\"][\"y_pred\"]).mean()\n",
    "\n",
    "print(\"optional_ms, independent of textual entailment:\", optional_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "451f5d0b-76bb-40ed-a356-0b4a6af9cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contra_ms without fine-tuning 84.7\n",
      "contra_ms with fine-tuning 92.38333333333334\n"
     ]
    }
   ],
   "source": [
    "contra_no_ft = (original_ms_no_ft + anti_ms_no_ft + optional_results)/0.03\n",
    "contra_with_ft = (original_ms_with_ft + anti_ms_with_ft + optional_results)/0.03\n",
    "\n",
    "print(\"contra_ms without fine-tuning\", contra_no_ft)\n",
    "print(\"contra_ms with fine-tuning\", contra_with_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9747205-3a9b-4198-bb25-c715b756c4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
