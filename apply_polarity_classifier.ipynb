{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047f67c2-ba69-415e-be50-9655d4cf2784",
   "metadata": {},
   "source": [
    "# Prepare Experiment & Deepspeed config (**MANDATORY**)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f9ab32-f86e-4830-ac5f-0b9dcd9fceb6",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 5e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 5e8,\n",
    "        \"contiguous_gradients\": True,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\",\n",
    "        },\n",
    "        \"offload_params\": {\n",
    "            \"device\": \"none\"\n",
    "        },\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 200,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"per_device_train_batch_size\": 128,\n",
    "    \"per_device_eval_batch_size\": 256,\n",
    "    \"fp16\": True,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"logging_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"save_total_limit\": 1,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"eval_accuracy\",\n",
    "    \"greater_is_better\": True,\n",
    "}\n",
    "\n",
    "# usually overriden by external config:\n",
    "num_gpus = 1\n",
    "model_name = \"data/models/polarity/bert-base-uncased/bs128_lr_1e-05/checkpoint-678/\"\n",
    "tokenizer_name = \"bert-base-uncased\"\n",
    "block_size = 128\n",
    "logdir = \"data/models/polarity/bert-base-uncased/bs128_lr_1e-05/\"\n",
    "override_logdir = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b194b8-be8d-44e3-90dc-27f3fe4d05ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 21:13:14.902592: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import datasets\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6193ccdf-bc57-42e5-9b21-ade4db40bee5",
   "metadata": {},
   "source": [
    "# Tokenize the dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c709d7-c6a8-4ac4-9280-9b3066705abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"Eleuther\" in model_name:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, bos_token='<|startoftext|>', \n",
    "                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf667f-472b-4027-8781-b030a953c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_social_chem101():\n",
    "    a = pd.read_csv(\"data/social-chem-101/social-chem-101.v1.0.tsv\", sep=\"\\t\")\n",
    "    return a\n",
    "\n",
    "social_chem = load_social_chem101()\n",
    "social_chem = social_chem[social_chem[\"split\"] == \"train\"]\n",
    "social_chem = social_chem.dropna(subset=[\"rot-categorization\", \"rot-judgment\", \"action\", \"rot-agree\", \"action-moral-judgment\"])\n",
    "social_chem = social_chem[social_chem[\"rot-agree\"] >= 3.0]\n",
    "social_chem = social_chem[social_chem[\"rot-bad\"] == 0]\n",
    "social_chem = social_chem[social_chem[\"rot-categorization\"].apply(lambda x: \"morality-ethics\" in x or \"social-norms\" in x)]\n",
    "social_chem = social_chem[social_chem[\"rot-judgment\"].apply(lambda x: \"{\" not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffca712-77e3-4491-8218-9cd492342c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_action_norm_split(path):\n",
    "    train, dev, test = [pd.read_json(f\"{path}{x}.jsonl\", lines=True) for x in [\"train\", \"dev\", \"test\"]]\n",
    "\n",
    "    # construct dataframes that can actually be used\n",
    "    assign_action = lambda x: x[\"moral_action\"] if x[\"label\"] == 1 else x[\"immoral_action\"]\n",
    "    train[\"action\"] = train.apply(assign_action, axis=1)\n",
    "    dev[\"action\"] = dev.apply(assign_action, axis=1)\n",
    "    test[\"action\"] = test.apply(assign_action, axis=1)\n",
    "    return train, dev, test\n",
    "\n",
    "# used for testing\n",
    "train, dev, test = load_action_norm_split(\"data/contrastive_moral_stories/original_ms/action+norm/norm_distance/\")\n",
    "opt_train, opt_dev, opt_test = load_action_norm_split(\"data/contrastive_moral_stories/optional_ms/action+norm/norm_distance/\")\n",
    "anti_train, anti_dev, anti_test = load_action_norm_split(\"data/contrastive_moral_stories/anti_ms/action+norm/norm_distance/\")\n",
    "#contra_train, contra_dev, contra_test = load_action_norm_split(\"data/contrastive_moral_stories/contra_ms/action+norm/norm_distance/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95850bc-2514-4fee-9636-98470b6413fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need labels for the norms...\n",
    "# obligatories: 1\n",
    "# impermissibles: 0\n",
    "# neutral: 2\n",
    "\n",
    "test = test.drop_duplicates(\"norm\").merge(social_chem, left_on=\"norm\", right_on=\"rot\").drop_duplicates(\"norm\")[[\"ID\", \"norm\", \"action-moral-judgment\"]]\n",
    "test[\"label\"] = (test[\"action-moral-judgment\"] > 0).astype(\"int\")\n",
    "\n",
    "anti_test = anti_test.drop_duplicates(\"norm\").merge(test[[\"ID\", \"action-moral-judgment\"]], on=\"ID\")\n",
    "\n",
    "anti_test[\"action-moral-judgment\"] = anti_test[\"action-moral-judgment\"].apply(lambda x: -1 * x)\n",
    "anti_test = anti_test[[\"ID\", \"norm\", \"action-moral-judgment\"]]\n",
    "# positive judgment implies obligatory norms...\n",
    "anti_test[\"label\"] = (anti_test[\"action-moral-judgment\"] > 0).astype(\"int\")\n",
    "\n",
    "t = set(anti_test[\"ID\"])\n",
    "opt_test = opt_test[opt_test[\"ID\"].apply(lambda x: x in t)][[\"ID\", \"norm\"]]\n",
    "opt_test[\"label\"] = 2\n",
    "\n",
    "contra_test = pd.concat([test, anti_test, opt_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbbc6395-11ae-4872-9b01-e0d208d11520",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict()\n",
    "dataset[\"original_ms\"] = datasets.Dataset.from_pandas(test)\n",
    "dataset[\"anti_ms\"] = datasets.Dataset.from_pandas(anti_test)\n",
    "dataset[\"optional_ms\"] = datasets.Dataset.from_pandas(opt_test)\n",
    "dataset[\"contra_ms\"] = datasets.Dataset.from_pandas(contra_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8cb7c-de02-4e36-bd84-d422d42dce04",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9963960-f5f4-46c1-852c-3cec290c2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d6987b-3367-46c8-985c-2b5cbf451fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset[\"original_ms\"].select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bcbc1a2-0c4e-4495-b95e-dc10ecd0bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def run_batch(batch):\n",
    "    x = tokenizer(batch[\"norm\"], padding=\"max_length\", return_tensors=\"pt\")\n",
    "    x = {k:v.cuda() for k,v in x.items()}\n",
    "    out = model(**x)\n",
    "    y_pred= torch.argmax(out.logits, axis=1).cpu().tolist()\n",
    "    return {\"y_pred\": y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367f7071-9540-4214-92cb-e2c11a168ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f452ef7f34ea481b8df127d370aac0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb10d99902c4014bf89d0fc7d0e513f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a968a6b099c8436c867b1f0baa1f7e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb508c2ae59483081ace03389a9c261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = dataset.map(run_batch, batched=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbbf9d01-23c9-4af7-b159-b11c6831522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc for split original_ms : 0.978\n",
      "Acc for split anti_ms : 0.961\n",
      "Acc for split optional_ms : 0.992\n",
      "Acc for split contra_ms : 0.977\n"
     ]
    }
   ],
   "source": [
    "for k in dataset.keys():\n",
    "    print(\"Acc for split\",k,\":\", (np.array(results[k][\"label\"]) == np.array(results[k][\"y_pred\"])).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8258686c-34d2-42a3-ad54-b0b2de83492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in dataset.keys():\n",
    "    results[split].to_pandas().to_csv(f\"{logdir}{split}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76e318-4be0-43f7-a724-dab1db87a65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
